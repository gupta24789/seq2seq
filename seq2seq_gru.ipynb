{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gupta24789/seq2seq/blob/main/seq2seq_gru.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KeD9zkHuDwT"
      },
      "source": [
        "## Machine Translation :  German to English"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7qVNPLEuDwX"
      },
      "outputs": [],
      "source": [
        "# !pip install evaluate\n",
        "# !python -m spacy download de_core_news_sm\n",
        "# !python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jins2wUVuDwZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK47PFbmuDwZ"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import random\n",
        "import itertools\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm , tqdm_notebook\n",
        "\n",
        "import evaluate\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46VcsCZruDwa"
      },
      "source": [
        "## Set Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6z5IGy-uDwa"
      },
      "outputs": [],
      "source": [
        "seed = 1234\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_IDeuBRuDwb"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "watJ_bjOuDwb",
        "outputId": "e8708ab4-14b1-4dbb-901f-2fecf4de7162"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((29000, 2), (1014, 2), (1000, 2))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"https://raw.githubusercontent.com/gupta24789/seq2seq/main/data/train.csv\")\n",
        "val_df = pd.read_csv(\"https://raw.githubusercontent.com/gupta24789/seq2seq/main/data/val.csv\")\n",
        "test_df = pd.read_csv(\"https://raw.githubusercontent.com/gupta24789/seq2seq/main/data/test.csv\")\n",
        "\n",
        "train_df.shape, val_df.shape, test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVKC6otpuDwc",
        "outputId": "9ff33f75-780e-4d96-f065-50d9e9f4c498"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>de</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two young, White males are outside near many b...</td>\n",
              "      <td>Zwei junge weiße Männer sind im Freien in der ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Several men in hard hats are operating a giant...</td>\n",
              "      <td>Mehrere Männer mit Schutzhelmen bedienen ein A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A little girl climbing into a wooden playhouse.</td>\n",
              "      <td>Ein kleines Mädchen klettert in ein Spielhaus ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en  \\\n",
              "0  Two young, White males are outside near many b...   \n",
              "1  Several men in hard hats are operating a giant...   \n",
              "2    A little girl climbing into a wooden playhouse.   \n",
              "\n",
              "                                                  de  \n",
              "0  Zwei junge weiße Männer sind im Freien in der ...  \n",
              "1  Mehrere Männer mit Schutzhelmen bedienen ein A...  \n",
              "2  Ein kleines Mädchen klettert in ein Spielhaus ...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n2qe6aNuDwc"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jK8gMrDBuDwd"
      },
      "outputs": [],
      "source": [
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "nlp_de = spacy.load(\"de_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwDQxVkluDwd",
        "outputId": "e57d2717-079d-436c-d899-bca5544c53ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['What', 'a', 'lovely', 'day', 'it', 'is', 'today', '!']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "string = \"What a lovely day it is today!\"\n",
        "\n",
        "[token.text for token in nlp_en.tokenizer(string)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKi4W9lMuDwe"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIYYoPOAuDwe"
      },
      "outputs": [],
      "source": [
        "def tokenized_text(text, nlp, max_length = 1000, is_lower = True):\n",
        "    if is_lower:\n",
        "        text = str(text).lower()\n",
        "    tokens = [token.text for token in nlp.tokenizer(text)]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7WtyHebuDwe"
      },
      "outputs": [],
      "source": [
        "train_df['en_tokens'] = train_df.en.map(lambda x: tokenized_text(x, nlp_en))\n",
        "train_df['de_tokens'] = train_df.de.map(lambda x: tokenized_text(x, nlp_de))\n",
        "\n",
        "## val\n",
        "val_df['en_tokens'] = val_df.en.map(lambda x: tokenized_text(x, nlp_en))\n",
        "val_df['de_tokens'] = val_df.de.map(lambda x: tokenized_text(x, nlp_de))\n",
        "## test\n",
        "test_df['en_tokens'] = test_df.en.map(lambda x: tokenized_text(x, nlp_en))\n",
        "test_df['de_tokens'] = test_df.de.map(lambda x: tokenized_text(x, nlp_de))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-iLnh3guDwf",
        "outputId": "076419f1-8370-4027-b532-1cd4a498309e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>de</th>\n",
              "      <th>en_tokens</th>\n",
              "      <th>de_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two young, White males are outside near many b...</td>\n",
              "      <td>Zwei junge weiße Männer sind im Freien in der ...</td>\n",
              "      <td>[two, young, ,, white, males, are, outside, ne...</td>\n",
              "      <td>[zwei, junge, weiße, männer, sind, im, freien,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Several men in hard hats are operating a giant...</td>\n",
              "      <td>Mehrere Männer mit Schutzhelmen bedienen ein A...</td>\n",
              "      <td>[several, men, in, hard, hats, are, operating,...</td>\n",
              "      <td>[mehrere, männer, mit, schutzhelmen, bedienen,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A little girl climbing into a wooden playhouse.</td>\n",
              "      <td>Ein kleines Mädchen klettert in ein Spielhaus ...</td>\n",
              "      <td>[a, little, girl, climbing, into, a, wooden, p...</td>\n",
              "      <td>[ein, kleines, mädchen, klettert, in, ein, spi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en  \\\n",
              "0  Two young, White males are outside near many b...   \n",
              "1  Several men in hard hats are operating a giant...   \n",
              "2    A little girl climbing into a wooden playhouse.   \n",
              "\n",
              "                                                  de  \\\n",
              "0  Zwei junge weiße Männer sind im Freien in der ...   \n",
              "1  Mehrere Männer mit Schutzhelmen bedienen ein A...   \n",
              "2  Ein kleines Mädchen klettert in ein Spielhaus ...   \n",
              "\n",
              "                                           en_tokens  \\\n",
              "0  [two, young, ,, white, males, are, outside, ne...   \n",
              "1  [several, men, in, hard, hats, are, operating,...   \n",
              "2  [a, little, girl, climbing, into, a, wooden, p...   \n",
              "\n",
              "                                           de_tokens  \n",
              "0  [zwei, junge, weiße, männer, sind, im, freien,...  \n",
              "1  [mehrere, männer, mit, schutzhelmen, bedienen,...  \n",
              "2  [ein, kleines, mädchen, klettert, in, ein, spi...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VfR4t3guDwf"
      },
      "source": [
        "## Build Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEljfSBKuDwg",
        "outputId": "7092b50a-82d2-49fc-fb0a-f2787977d42a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "en_vocab : 9795\n",
            "de_vocab : 18669\n"
          ]
        }
      ],
      "source": [
        "special_words = [\"<unk>\",\"<pad>\", \"<sos>\",\"<eos>\"]\n",
        "en_words = list(set(itertools.chain.from_iterable(train_df.en_tokens.tolist())))\n",
        "de_words = list(set(itertools.chain.from_iterable(train_df.de_tokens.tolist())))\n",
        "\n",
        "en_words = special_words + en_words\n",
        "de_words = special_words + de_words\n",
        "\n",
        "en_vocab = {w:i for i,w in enumerate(en_words)}\n",
        "de_vocab = {w:i for i,w in enumerate(de_words)}\n",
        "\n",
        "UNK_ID = en_vocab['<unk>']\n",
        "PAD_ID = en_vocab['<pad>']\n",
        "SOS_ID = en_vocab['<sos>']\n",
        "EOS_ID = en_vocab['<eos>']\n",
        "\n",
        "print(f\"en_vocab : {len(en_vocab)}\")\n",
        "print(f\"de_vocab : {len(de_vocab)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iMLuFttuDwg"
      },
      "source": [
        "## Encode text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOMiRmybuDwh"
      },
      "outputs": [],
      "source": [
        "def encode_text(tokens, vocab, is_add_sos = True, is_add_eos = True):\n",
        "    encoded = []\n",
        "    for w in tokens:\n",
        "        encoded.append(vocab.get(w, UNK_ID))\n",
        "\n",
        "    if is_add_sos:\n",
        "        encoded = [SOS_ID] + encoded\n",
        "    if is_add_eos:\n",
        "        encoded =  encoded + [EOS_ID]\n",
        "    return encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XWJHVNjuDwh"
      },
      "outputs": [],
      "source": [
        "train_df['en_encoded'] = train_df.en_tokens.apply(lambda x: encode_text(x, en_vocab))\n",
        "train_df['de_encoded'] = train_df.de_tokens.apply(lambda x: encode_text(x, de_vocab))\n",
        "\n",
        "## val\n",
        "val_df['en_encoded'] = val_df.en_tokens.apply(lambda x: encode_text(x, en_vocab))\n",
        "val_df['de_encoded'] = val_df.de_tokens.apply(lambda x: encode_text(x, de_vocab))\n",
        "## test\n",
        "test_df['en_encoded'] = test_df.en_tokens.apply(lambda x: encode_text(x, en_vocab))\n",
        "test_df['de_encoded'] = test_df.de_tokens.apply(lambda x: encode_text(x, de_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2PDs4DPuDwh",
        "outputId": "8941180a-727c-4620-edb2-33088239f6dd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>de</th>\n",
              "      <th>en_tokens</th>\n",
              "      <th>de_tokens</th>\n",
              "      <th>en_encoded</th>\n",
              "      <th>de_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two young, White males are outside near many b...</td>\n",
              "      <td>Zwei junge weiße Männer sind im Freien in der ...</td>\n",
              "      <td>[two, young, ,, white, males, are, outside, ne...</td>\n",
              "      <td>[zwei, junge, weiße, männer, sind, im, freien,...</td>\n",
              "      <td>[2, 4525, 2494, 6023, 591, 3214, 5611, 2053, 2...</td>\n",
              "      <td>[2, 9631, 12850, 6087, 17567, 12552, 17569, 12...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Several men in hard hats are operating a giant...</td>\n",
              "      <td>Mehrere Männer mit Schutzhelmen bedienen ein A...</td>\n",
              "      <td>[several, men, in, hard, hats, are, operating,...</td>\n",
              "      <td>[mehrere, männer, mit, schutzhelmen, bedienen,...</td>\n",
              "      <td>[2, 6028, 9729, 8160, 3203, 2546, 5611, 9332, ...</td>\n",
              "      <td>[2, 2833, 17567, 11574, 5083, 18477, 9541, 239...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A little girl climbing into a wooden playhouse.</td>\n",
              "      <td>Ein kleines Mädchen klettert in ein Spielhaus ...</td>\n",
              "      <td>[a, little, girl, climbing, into, a, wooden, p...</td>\n",
              "      <td>[ein, kleines, mädchen, klettert, in, ein, spi...</td>\n",
              "      <td>[2, 7307, 2193, 4520, 6500, 7255, 7307, 1912, ...</td>\n",
              "      <td>[2, 9541, 17600, 7526, 10294, 15634, 9541, 144...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en  \\\n",
              "0  Two young, White males are outside near many b...   \n",
              "1  Several men in hard hats are operating a giant...   \n",
              "2    A little girl climbing into a wooden playhouse.   \n",
              "\n",
              "                                                  de  \\\n",
              "0  Zwei junge weiße Männer sind im Freien in der ...   \n",
              "1  Mehrere Männer mit Schutzhelmen bedienen ein A...   \n",
              "2  Ein kleines Mädchen klettert in ein Spielhaus ...   \n",
              "\n",
              "                                           en_tokens  \\\n",
              "0  [two, young, ,, white, males, are, outside, ne...   \n",
              "1  [several, men, in, hard, hats, are, operating,...   \n",
              "2  [a, little, girl, climbing, into, a, wooden, p...   \n",
              "\n",
              "                                           de_tokens  \\\n",
              "0  [zwei, junge, weiße, männer, sind, im, freien,...   \n",
              "1  [mehrere, männer, mit, schutzhelmen, bedienen,...   \n",
              "2  [ein, kleines, mädchen, klettert, in, ein, spi...   \n",
              "\n",
              "                                          en_encoded  \\\n",
              "0  [2, 4525, 2494, 6023, 591, 3214, 5611, 2053, 2...   \n",
              "1  [2, 6028, 9729, 8160, 3203, 2546, 5611, 9332, ...   \n",
              "2  [2, 7307, 2193, 4520, 6500, 7255, 7307, 1912, ...   \n",
              "\n",
              "                                          de_encoded  \n",
              "0  [2, 9631, 12850, 6087, 17567, 12552, 17569, 12...  \n",
              "1  [2, 2833, 17567, 11574, 5083, 18477, 9541, 239...  \n",
              "2  [2, 9541, 17600, 7526, 10294, 15634, 9541, 144...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_G0fN5OuDwi"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkF9vbnpuDwi"
      },
      "outputs": [],
      "source": [
        "train_data = train_df[['en_encoded','de_encoded']].to_dict('records')\n",
        "val_data = val_df[['en_encoded','de_encoded']].to_dict('records')\n",
        "test_data = test_df[['en_encoded','de_encoded']].to_dict('records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXu-QBWPuDwj",
        "outputId": "bf9634a9-fe63-4133-ab15-12f631e67d30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'de_encoded': [2, 9631, 12850, 6087, 17567, 12552, 17569, 12147, 15634, 17501,\n",
            "                 10171, 17078, 9692, 3315, 3],\n",
            "  'en_encoded': [2, 4525, 2494, 6023, 591, 3214, 5611, 2053, 243, 2871, 8517,\n",
            "                 1705, 3]},\n",
            " {'de_encoded': [2, 2833, 17567, 11574, 5083, 18477, 9541, 2391, 3315, 3],\n",
            "  'en_encoded': [2, 6028, 9729, 8160, 3203, 2546, 5611, 9332, 7307, 2805, 7408,\n",
            "                 14, 1705, 3]}]\n"
          ]
        }
      ],
      "source": [
        "pprint(train_data[:2], compact=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xuzmc3cVuDwj"
      },
      "outputs": [],
      "source": [
        "def custom_collate(batch):\n",
        "    \"\"\"\n",
        "    Dynamic padding : find the max len in the batch and do the padding\n",
        "    \"\"\"\n",
        "    en_batch = [torch.tensor(item['en_encoded']) for item in batch]\n",
        "    de_batch = [torch.tensor(item['de_encoded']) for item in batch]\n",
        "\n",
        "    padded_en = nn.utils.rnn.pad_sequence(en_batch, batch_first= True, padding_value= PAD_ID)\n",
        "    padded_de = nn.utils.rnn.pad_sequence(de_batch, batch_first= True, padding_value= PAD_ID)\n",
        "\n",
        "    return {\"padded_en\": padded_en, \"padded_de\":  padded_de}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQC6oro0uDwj",
        "outputId": "4096a41b-d506-468e-b694-d64cf4f89f41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 14]) torch.Size([3, 15])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 3\n",
        "train_dl = DataLoader(train_data , batch_size = batch_size, shuffle = False, collate_fn= custom_collate)\n",
        "example = next(iter(train_dl))\n",
        "padded_en, padded_de = example['padded_en'],example['padded_de']\n",
        "print(padded_en.shape, padded_de.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhHC4B4FuDwk",
        "outputId": "267d6f69-3de4-4517-a725-5b7416990898"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[   2, 4525, 2494, 6023,  591, 3214, 5611, 2053,  243, 2871, 8517, 1705,\n",
              "            3,    1],\n",
              "        [   2, 6028, 9729, 8160, 3203, 2546, 5611, 9332, 7307, 2805, 7408,   14,\n",
              "         1705,    3],\n",
              "        [   2, 7307, 2193, 4520, 6500, 7255, 7307, 1912, 4069, 1705,    3,    1,\n",
              "            1,    1]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWqPdFhTuDwk",
        "outputId": "f6b1de45-0b98-4996-f6bc-d7b3545ac584"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[    2,  9631, 12850,  6087, 17567, 12552, 17569, 12147, 15634, 17501,\n",
              "         10171, 17078,  9692,  3315,     3],\n",
              "        [    2,  2833, 17567, 11574,  5083, 18477,  9541,  2391,  3315,     3,\n",
              "             1,     1,     1,     1,     1],\n",
              "        [    2,  9541, 17600,  7526, 10294, 15634,  9541, 14413, 15413, 10444,\n",
              "          3315,     3,     1,     1,     1]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_de"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbQFCwaEuDwk"
      },
      "outputs": [],
      "source": [
        "## dataloaders\n",
        "batch_size = 256\n",
        "train_dl = DataLoader(train_data , batch_size = batch_size, shuffle = True, collate_fn= custom_collate)\n",
        "val_dl = DataLoader(val_data , batch_size = batch_size, shuffle = False, collate_fn= custom_collate)\n",
        "test_dl = DataLoader(test_data , batch_size = batch_size, shuffle = False, collate_fn= custom_collate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGiAEMJxuDwl"
      },
      "source": [
        "## Building Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jf419gYmuDwl"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Encode German text\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, dropout=dropout, batch_first= True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        # batch = [batch size, sent len]\n",
        "        embedded = self.dropout(self.embedding(batch))\n",
        "        # embedded = [batch size, sent len, embedding dim]\n",
        "        # print(f\"embedded : {embedded.shape}\")\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        # print(f\"outputs : {outputs.shape}\")\n",
        "        # print(f\"hidden : {hidden.shape}\")\n",
        "         # no cell state in GRU!\n",
        "        # outputs = [batch size, sent len, hidden dim * n directions]\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # outputs are always from the top hidden layer\n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSsFQK9JuDwl",
        "outputId": "7703fbfe-78fe-4c5e-d8b8-97392ae6b696"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : torch.Size([3, 15])\n",
            "torch.Size([1, 3, 64])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ],
      "source": [
        "## Enoder\n",
        "print(f\"Input : {padded_de.shape}\")\n",
        "encoder = Encoder(vocab_size = len(de_vocab), emb_dim = 100, hidden_dim=64,dropout=0.1)\n",
        "hidden = encoder(padded_de)\n",
        "print(hidden.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha5cRJAkuDwm"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim + hidden_dim, hidden_dim, dropout=dropout,  batch_first= True)\n",
        "        self.fc_out = nn.Linear(emb_dim + hidden_dim * 2, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, context):\n",
        "\n",
        "        # input = [batch size]\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # context = [n layers * n directions, batch size, hidden dim]\n",
        "        # n layers and n directions in the decoder will both always be 1, therefore:\n",
        "        # hidden = [1, batch size, hidden dim]\n",
        "        # context = [1, batch size, hidden dim]\n",
        "\n",
        "        # print(f\"Input : {input.shape}\")\n",
        "        # print(f'hidden : {hidden.shape}')\n",
        "        # print(f'context : {context.shape}')\n",
        "\n",
        "        input = input.unsqueeze(1)\n",
        "        # print(f\"Input -1 : {input.shape}\")\n",
        "        # input = [batch size, 1]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # print(\"embedded : \", embedded.shape)\n",
        "        # embedded = [batch size, 1, embedding dim]\n",
        "\n",
        "        emb_con = torch.cat((embedded, context.permute(1,0,2)), dim=2)\n",
        "        # print(f\"emb con : {emb_con.shape}\")\n",
        "        # emb_con = [batch size, 1, embedding dim + hidden dim]\n",
        "\n",
        "        output, hidden = self.rnn(emb_con, hidden)\n",
        "        # print(f\"output : {output.shape}\")\n",
        "        # print(f\"hidden  : {hidden.shape}\")\n",
        "        # output = [batch size, seq length, hidden dim * n directions]\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        # output = [batch size, 1, hidden dim]\n",
        "        # hidden = [1, batch size, hidden dim]\n",
        "\n",
        "        output = torch.cat((embedded.permute(1,0,2).squeeze(0), hidden.squeeze(0), context.squeeze(0)), dim=1).squeeze(0)\n",
        "        # print(output.shape)\n",
        "        # output = [batch size, embedding dim + hidden dim * 2]\n",
        "        prediction = self.fc_out(output)\n",
        "        # prediction = [batch size, output dim]\n",
        "        return prediction, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9R1tqhSFuDwm",
        "outputId": "4fbffea1-3532-40db-9254-b6e010f8824f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 9795]), torch.Size([1, 3, 64]))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Decoder\n",
        "## de[:,0] -> first input\n",
        "decoder = Decoder(vocab_size = len(en_vocab), emb_dim = 100, hidden_dim=64, dropout=0.1)\n",
        "prediction, hidden = decoder(padded_en[:,0], hidden, hidden)\n",
        "prediction.shape, hidden.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBkNtAqmuDwn"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio):\n",
        "        # src = [batch size, sent len]\n",
        "        # trg = [batch size, sent len]\n",
        "        # teacher_forcing_ratio is probability to use teacher forcing\n",
        "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_length = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.vocab_size\n",
        "        # tensor to store decoder outputs\n",
        "        outputs = torch.zeros(batch_size,trg_length,trg_vocab_size).to(self.device)\n",
        "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden = self.encoder(src)\n",
        "        context = hidden\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # context = [n layers * n directions, batch size, hidden dim]\n",
        "        # first input to the decoder is the <sos> tokens\n",
        "        input = trg[:,0]\n",
        "        # input = [batch size]\n",
        "        for t in range(1, trg_length):\n",
        "            # insert input token embedding, previous hidden and previous cell states\n",
        "            # receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden = self.decoder(input, hidden, context)\n",
        "            # output = [batch size, output dim]\n",
        "            # hidden = [n layers, batch size, hidden dim]\n",
        "            # cell = [n layers, batch size, hidden dim]\n",
        "            # place predictions in a tensor holding predictions for each token\n",
        "            output = output.squeeze(dim = 1)\n",
        "            outputs[:,t,:] = output\n",
        "            # decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            # get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1)\n",
        "            # if teacher forcing, use actual next token as next input\n",
        "            # if not, use predicted token\n",
        "            input = trg[:,t] if teacher_force else top1\n",
        "            # input = [batch size]\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf1-w9HxuDwn"
      },
      "outputs": [],
      "source": [
        "# model = Seq2Seq(encoder, decoder, device = \"cpu\")\n",
        "# outputs = model(padded_de, padded_en, teacher_forcing_ratio = True)\n",
        "# print(outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhw09j-wuDwo"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOqucAzNuDwo"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqLightningModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, encode, decoder, learning_rate, device, teacher_forcing_ratio):\n",
        "        super().__init__()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.seq2seq_model = Seq2Seq(self.encoder, self.decoder, device)\n",
        "        self.loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
        "        self.init_weights()\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "        self.test_loss = []\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.named_parameters():\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "\n",
        "    def forward(self, de, en):\n",
        "        logits = self.seq2seq_model(de, en, teacher_forcing_ratio = self.teacher_forcing_ratio)\n",
        "        return logits\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        src, trg = batch['padded_de'], batch['padded_en']\n",
        "        output = self(src, trg)\n",
        "        # output = [trg length, batch size, trg vocab size]\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
        "        trg = trg[1:].view(-1)\n",
        "        # trg = [(trg length - 1) * batch size]\n",
        "        # print(output.shape, trg.shape)\n",
        "        loss = self.loss_fn(output, trg)\n",
        "        self.train_loss.append(loss.item())\n",
        "        self.log_dict({\"train_loss\": loss}, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        src, trg = batch['padded_de'], batch['padded_en']\n",
        "        output = self(src, trg)\n",
        "        # output = [trg length, batch size, trg vocab size]\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
        "        trg = trg[1:].view(-1)\n",
        "        # trg = [(trg length - 1) * batch size]\n",
        "        loss = self.loss_fn(output, trg)\n",
        "        self.val_loss.append(loss.item())\n",
        "        self.log_dict({\"val_loss\": loss}, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        print(f\"Epoch : {self.current_epoch}  \\\n",
        "              Train Loss : {np.mean(self.train_loss)} \\\n",
        "              Val Loss : {np.mean(self.val_loss)} \\\n",
        "              Train PPL : {np.exp(np.mean(self.train_loss))} \\\n",
        "              Val PPL : {np.exp(np.mean(self.val_loss))} \")\n",
        "\n",
        "        self.train_loss =[]\n",
        "        self.val_loss =[]\n",
        "\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        src, trg = batch['padded_de'], batch['padded_en']\n",
        "        output = self(src, trg)\n",
        "        # output = [trg length, batch size, trg vocab size]\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
        "        trg = trg[1:].view(-1)\n",
        "        # trg = [(trg length - 1) * batch size]\n",
        "        loss = self.loss_fn(output, trg)\n",
        "        self.test_loss.append(loss.item())\n",
        "        return loss\n",
        "\n",
        "    def on_test_epoch_end(self) -> None:\n",
        "        print(f\"Test Loss : {np.mean(self.test_loss)}  Test PPL : {np.exp(np.mean(self.test_loss))}\")\n",
        "        self.test_loss = []\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt = optim.Adam(self.parameters(), lr = self.learning_rate)\n",
        "        return opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gtw_Y_tHuDwp",
        "outputId": "7345b417-d7db-4335-cc9e-050ff0746cf8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 14, 9795])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## test architecture\n",
        "encoder = Encoder(vocab_size = len(de_vocab), emb_dim = 256, hidden_dim=512, dropout=0.5)\n",
        "decoder = Decoder(vocab_size = len(en_vocab), emb_dim = 256, hidden_dim=512, dropout=0.5)\n",
        "model = Seq2SeqLightningModel(encoder, decoder, learning_rate= .001, device =\"cpu\", teacher_forcing_ratio=0.5)\n",
        "outputs = model(padded_de, padded_en)\n",
        "outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmeDr_tnuDwq",
        "outputId": "324e3d89-d57e-4008-ad3a-43415f30114b",
        "colab": {
          "referenced_widgets": [
            "5e4396979c95474db651fe20b1ca7c82",
            "a725c5d84d6c4ee1a2c90f0d83c60f8d",
            "5892ece782c84cf39bfa34db7c8a26bf",
            "b49b40c8a7f44a378d60949f6781fcca",
            "b65239e8a9564f3794b42b68c48770c6",
            "a788295a2e06465693247a4c8e834cd8",
            "5b2cf617c8324b6eb3ef1d103bf7c979"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
            "\n",
            "  | Name          | Type             | Params\n",
            "---------------------------------------------------\n",
            "0 | encoder       | Encoder          | 6.9 M \n",
            "1 | decoder       | Decoder          | 18.0 M\n",
            "2 | seq2seq_model | Seq2Seq          | 24.8 M\n",
            "3 | loss_fn       | CrossEntropyLoss | 0     \n",
            "---------------------------------------------------\n",
            "24.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "24.8 M    Total params\n",
            "99.218    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e4396979c95474db651fe20b1ca7c82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 0                Train Loss : nan               Val Loss : 9.18659782409668               Train PPL : nan               Val PPL : 9765.370889417609 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a725c5d84d6c4ee1a2c90f0d83c60f8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5892ece782c84cf39bfa34db7c8a26bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 1                Train Loss : 5.42063157600269               Val Loss : 5.022166967391968               Train PPL : 226.02182739506364               Val PPL : 151.73976290370982 \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b49b40c8a7f44a378d60949f6781fcca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 3                Train Loss : 4.790816967947441               Val Loss : 4.609658598899841               Train PPL : 120.39969118315156               Val PPL : 100.44985009243915 \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b65239e8a9564f3794b42b68c48770c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 5                Train Loss : 4.392380410119107               Val Loss : 4.313825607299805               Train PPL : 80.83260489973121               Val PPL : 74.72581444191289 \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a788295a2e06465693247a4c8e834cd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 7                Train Loss : 3.9589707014853492               Val Loss : 3.9980509281158447               Train PPL : 52.40335947998493               Val PPL : 54.491837952586906 \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b2cf617c8324b6eb3ef1d103bf7c979",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 9                Train Loss : 3.5317980302007577               Val Loss : 3.7198106050491333               Train PPL : 34.18537873207244               Val PPL : 41.25657958075547 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        }
      ],
      "source": [
        "## clear old checkpoints\n",
        "checkpoints_dir = \"checkpoints_logs\"\n",
        "if os.path.exists(checkpoints_dir):\n",
        "    shutil.rmtree(checkpoints_dir)\n",
        "\n",
        "## Model Training\n",
        "encoder = Encoder(vocab_size = len(de_vocab), emb_dim = 300, hidden_dim=512, dropout=0.5)\n",
        "decoder = Decoder(vocab_size = len(en_vocab), emb_dim = 300, hidden_dim=512, dropout=0.5)\n",
        "model = Seq2SeqLightningModel(encoder, decoder, learning_rate= .001, device =\"cuda\", teacher_forcing_ratio=0.5)\n",
        "\n",
        "callbacks = pl.callbacks.ModelCheckpoint(dirpath = checkpoints_dir,\n",
        "                                         filename = '{epoch}-{val_loss:.2f}',\n",
        "                                          mode = \"min\",\n",
        "                                          monitor = \"val_loss\",\n",
        "                                          save_last = True,\n",
        "                                          save_top_k=-1)\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(accelerator= \"gpu\",\n",
        "           max_epochs=10,\n",
        "           check_val_every_n_epoch = 2,\n",
        "           gradient_clip_val=1,\n",
        "           gradient_clip_algorithm=\"value\",\n",
        "           callbacks = [callbacks])\n",
        "\n",
        "trainer.fit(model, train_dl, val_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZNe7gXjuDwq",
        "outputId": "7251b366-781e-49d3-db0a-656055ac9d7f",
        "colab": {
          "referenced_widgets": [
            "7f47ae03587d497fb973f78531bdf6fb"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f47ae03587d497fb973f78531bdf6fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss : 3.7403244376182556  Test PPL : 42.11165055251135\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## if test dataset has loss near around val loss that means we are not overfitting\n",
        "model = model.eval()\n",
        "trainer.test(model, dataloaders= test_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsQjIQ_yuDwq"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDJcHQnIuDwr"
      },
      "outputs": [],
      "source": [
        "en_vocab_lookup = {i:w for w,i in en_vocab.items()}\n",
        "\n",
        "def encode_tokens(tokens, vocab):\n",
        "    encoded = []\n",
        "    for w in tokens:\n",
        "        encoded.append(vocab.get(w, UNK_ID))\n",
        "    return encoded\n",
        "\n",
        "\n",
        "def decode_tokens(tokens, vocab_loopup):\n",
        "    decoded = []\n",
        "    for i in tokens:\n",
        "        if i == 2 or i==3:\n",
        "            continue\n",
        "        decoded.append(vocab_loopup.get(i))\n",
        "    return decoded\n",
        "\n",
        "\n",
        "def translate_sentence(sentence, model, en_nlp, de_nlp, en_vocab, de_vocab, sos_token, eos_token, device, lower = True, max_output_length=25):\n",
        "    ## model eval mode\n",
        "    model.eval()\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    ## encode german sent\n",
        "    sent = str(sentence).lower() if lower else sentence\n",
        "    tokens = [token.text for token in de_nlp.tokenizer(sent)]\n",
        "    tokens = [sos_token] + tokens + [eos_token]\n",
        "    ids = encode_tokens(tokens, de_vocab)\n",
        "\n",
        "    ## encoder input\n",
        "    tensor = torch.LongTensor(ids).unsqueeze(0).to(device)\n",
        "    tensor = tensor.to(device)\n",
        "\n",
        "    ## encoder\n",
        "    hidden = model.encoder(tensor)\n",
        "\n",
        "    ## input to decoder <sos>\n",
        "    inputs = encode_tokens([sos_token], en_vocab)\n",
        "\n",
        "    for _ in range(max_output_length):\n",
        "        inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
        "        output, hidden = model.decoder(inputs_tensor, hidden, hidden)\n",
        "        predicted_token = output.argmax(-1).item()\n",
        "        inputs.append(predicted_token)\n",
        "        if predicted_token == en_vocab[eos_token]:\n",
        "            break\n",
        "\n",
        "    tokens = decode_tokens(inputs, en_vocab_lookup)\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EWrAfZUuDwr",
        "outputId": "4faac819-e787-4375-ba1f-a481f1503e37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'man', 'in', 'a', 'green', 'jacket', 'is']\n"
          ]
        }
      ],
      "source": [
        "sent = \"Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.\"\n",
        "predictions = translate_sentence(sent, model, nlp_en, nlp_de, en_vocab, de_vocab, sos_token=\"<sos>\", eos_token=\"<eos>\", device = \"cuda\")\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC-Mwc5EuDws"
      },
      "source": [
        "## Blue Scroe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAGoRsgIuDws"
      },
      "outputs": [],
      "source": [
        "bleu = evaluate.load(\"bleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPt2wBh3uDws",
        "outputId": "daafb935-a41d-4695-a0bb-7dfe578715c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a man in an orange hat starring at something.',\n",
            " 'a boston terrier is running on lush green grass in front of a white fence.']\n"
          ]
        }
      ],
      "source": [
        "references = test_df.en.str.lower().tolist()\n",
        "pprint(references[:2], compact=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9lIgHpRuDwt",
        "outputId": "c8c0a519-b8a9-4a96-8fc5-f46216cec9eb",
        "colab": {
          "referenced_widgets": [
            "20aa7327f0eb4154af29193e11f900ca"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_15685/1643434524.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  prediction_list = [translate_sentence(sent, model, nlp_en, nlp_de, en_vocab, de_vocab, sos_token=\"<sos>\", eos_token=\"<eos>\", device = \"cuda\") for sent in tqdm_notebook(test_df.de.values)]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20aa7327f0eb4154af29193e11f900ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prediction_list = []\n",
        "prediction_list = [translate_sentence(sent, model, nlp_en, nlp_de, en_vocab, de_vocab, sos_token=\"<sos>\", eos_token=\"<eos>\", device = \"cuda\") for sent in tqdm_notebook(test_df.de.values)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riBWXtaNuDwt",
        "outputId": "ade772ca-4f44-4c36-cf8b-27e25d77bfc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['a', 'man', 'in', 'a', 'green', 'jacket', 'is'],\n",
            " ['a', 'brown', 'dog', 'runs', 'through', 'a', 'grassy', 'field', '.']]\n"
          ]
        }
      ],
      "source": [
        "pprint(prediction_list[:2], compact = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d3CtV_quDwu"
      },
      "outputs": [],
      "source": [
        "def get_tokenizer_fn(nlp, lower):\n",
        "    def tokenizer_fn(s):\n",
        "        tokens = [token.text for token in nlp.tokenizer(s)]\n",
        "        if lower:\n",
        "            tokens = [token.lower() for token in tokens]\n",
        "        return tokens\n",
        "\n",
        "    return tokenizer_fn\n",
        "\n",
        "tokenizer_fn = get_tokenizer_fn(nlp_en,  lower = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uCaOWNuuDwu"
      },
      "outputs": [],
      "source": [
        "predictions = list(map(lambda x: \" \".join(x),prediction_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV-3hrl3uDwu",
        "outputId": "6bb17b52-d1d3-4d9c-db6e-b5160f7c0f80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bleu': 0.07709181260649708,\n",
              " 'precisions': [0.5672100165367352,\n",
              "  0.1994374497723011,\n",
              "  0.08304979894834519,\n",
              "  0.03293084522502744],\n",
              " 'brevity_penalty': 0.5812798123625764,\n",
              " 'length_ratio': 0.6482885366413967,\n",
              " 'translation_length': 8466,\n",
              " 'reference_length': 13059}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = bleu.compute(predictions=predictions, references=references, tokenizer=tokenizer_fn)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBwPraIVuDwv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lighting",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}