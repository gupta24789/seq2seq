{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gupta24789/seq2seq/blob/main/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wydka58uJBB8"
      },
      "source": [
        "## Machine Translation :  German to English"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOI--2DhJBB9"
      },
      "outputs": [],
      "source": [
        "# !pip install evaluate\n",
        "# !python -m spacy download de_core_news_sm\n",
        "# !python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McjjzyAKJBB-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wkJNAJdJBB_"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import random\n",
        "import itertools\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm , tqdm_notebook\n",
        "\n",
        "import evaluate\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKZEwXI4JBB_"
      },
      "source": [
        "## Set Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhvzcB5fJBB_"
      },
      "outputs": [],
      "source": [
        "seed = 1234\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQGcnTbXJBCA"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kek1LftHJBCA",
        "outputId": "499f419d-846a-47c0-d598-edd619f3c1c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((29000, 2), (1014, 2), (1000, 2))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"https://raw.githubusercontent.com/gupta24789/seq2seq/main/data/train.csv\")\n",
        "val_df = pd.read_csv(\"https://raw.githubusercontent.com/gupta24789/seq2seq/main/data/val.csv\")\n",
        "test_df = pd.read_csv(\"https://raw.githubusercontent.com/gupta24789/seq2seq/main/data/test.csv\")\n",
        "\n",
        "train_df.shape, val_df.shape, test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7r0362tJBCA",
        "outputId": "b206d5de-5416-415c-a861-998032650550"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>de</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two young, White males are outside near many b...</td>\n",
              "      <td>Zwei junge weiße Männer sind im Freien in der ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Several men in hard hats are operating a giant...</td>\n",
              "      <td>Mehrere Männer mit Schutzhelmen bedienen ein A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A little girl climbing into a wooden playhouse.</td>\n",
              "      <td>Ein kleines Mädchen klettert in ein Spielhaus ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en  \\\n",
              "0  Two young, White males are outside near many b...   \n",
              "1  Several men in hard hats are operating a giant...   \n",
              "2    A little girl climbing into a wooden playhouse.   \n",
              "\n",
              "                                                  de  \n",
              "0  Zwei junge weiße Männer sind im Freien in der ...  \n",
              "1  Mehrere Männer mit Schutzhelmen bedienen ein A...  \n",
              "2  Ein kleines Mädchen klettert in ein Spielhaus ...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDMryJK7JBCA"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gifU9WNDJBCB"
      },
      "outputs": [],
      "source": [
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "nlp_de = spacy.load(\"de_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYXdfF1AJBCB",
        "outputId": "de921f65-fa8c-4e08-cca7-c007126a11f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['What', 'a', 'lovely', 'day', 'it', 'is', 'today', '!']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "string = \"What a lovely day it is today!\"\n",
        "\n",
        "[token.text for token in nlp_en.tokenizer(string)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aNeynrpJBCB"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PazOiwaXJBCB"
      },
      "outputs": [],
      "source": [
        "def tokenized_text(text, nlp, max_length = 1000, is_lower = True):\n",
        "    if is_lower:\n",
        "        text = str(text).lower()\n",
        "    tokens = [token.text for token in nlp.tokenizer(text)]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxAdf4LAJBCB"
      },
      "outputs": [],
      "source": [
        "train_df['en_tokens'] = train_df.en.map(lambda x: tokenized_text(x, nlp_en))\n",
        "train_df['de_tokens'] = train_df.de.map(lambda x: tokenized_text(x, nlp_de))\n",
        "\n",
        "## val\n",
        "val_df['en_tokens'] = val_df.en.map(lambda x: tokenized_text(x, nlp_en))\n",
        "val_df['de_tokens'] = val_df.de.map(lambda x: tokenized_text(x, nlp_de))\n",
        "## test\n",
        "test_df['en_tokens'] = test_df.en.map(lambda x: tokenized_text(x, nlp_en))\n",
        "test_df['de_tokens'] = test_df.de.map(lambda x: tokenized_text(x, nlp_de))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NiSz8rzJBCB",
        "outputId": "41824047-6e3c-47ce-9725-65ec9be29291"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>de</th>\n",
              "      <th>en_tokens</th>\n",
              "      <th>de_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two young, White males are outside near many b...</td>\n",
              "      <td>Zwei junge weiße Männer sind im Freien in der ...</td>\n",
              "      <td>[two, young, ,, white, males, are, outside, ne...</td>\n",
              "      <td>[zwei, junge, weiße, männer, sind, im, freien,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Several men in hard hats are operating a giant...</td>\n",
              "      <td>Mehrere Männer mit Schutzhelmen bedienen ein A...</td>\n",
              "      <td>[several, men, in, hard, hats, are, operating,...</td>\n",
              "      <td>[mehrere, männer, mit, schutzhelmen, bedienen,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A little girl climbing into a wooden playhouse.</td>\n",
              "      <td>Ein kleines Mädchen klettert in ein Spielhaus ...</td>\n",
              "      <td>[a, little, girl, climbing, into, a, wooden, p...</td>\n",
              "      <td>[ein, kleines, mädchen, klettert, in, ein, spi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en  \\\n",
              "0  Two young, White males are outside near many b...   \n",
              "1  Several men in hard hats are operating a giant...   \n",
              "2    A little girl climbing into a wooden playhouse.   \n",
              "\n",
              "                                                  de  \\\n",
              "0  Zwei junge weiße Männer sind im Freien in der ...   \n",
              "1  Mehrere Männer mit Schutzhelmen bedienen ein A...   \n",
              "2  Ein kleines Mädchen klettert in ein Spielhaus ...   \n",
              "\n",
              "                                           en_tokens  \\\n",
              "0  [two, young, ,, white, males, are, outside, ne...   \n",
              "1  [several, men, in, hard, hats, are, operating,...   \n",
              "2  [a, little, girl, climbing, into, a, wooden, p...   \n",
              "\n",
              "                                           de_tokens  \n",
              "0  [zwei, junge, weiße, männer, sind, im, freien,...  \n",
              "1  [mehrere, männer, mit, schutzhelmen, bedienen,...  \n",
              "2  [ein, kleines, mädchen, klettert, in, ein, spi...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oijemAu-JBCC"
      },
      "source": [
        "## Build Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6CwhLGBJBCC",
        "outputId": "4ba1fa14-7a29-4810-d0d2-9bff821e8c75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "en_vocab : 9795\n",
            "de_vocab : 18669\n"
          ]
        }
      ],
      "source": [
        "special_words = [\"<unk>\",\"<pad>\", \"<sos>\",\"<eos>\"]\n",
        "en_words = list(set(itertools.chain.from_iterable(train_df.en_tokens.tolist())))\n",
        "de_words = list(set(itertools.chain.from_iterable(train_df.de_tokens.tolist())))\n",
        "\n",
        "en_words = special_words + en_words\n",
        "de_words = special_words + de_words\n",
        "\n",
        "en_vocab = {w:i for i,w in enumerate(en_words)}\n",
        "de_vocab = {w:i for i,w in enumerate(de_words)}\n",
        "\n",
        "UNK_ID = en_vocab['<unk>']\n",
        "PAD_ID = en_vocab['<pad>']\n",
        "SOS_ID = en_vocab['<sos>']\n",
        "EOS_ID = en_vocab['<eos>']\n",
        "\n",
        "print(f\"en_vocab : {len(en_vocab)}\")\n",
        "print(f\"de_vocab : {len(de_vocab)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG8o7Xe4JBCC"
      },
      "source": [
        "## Encode text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nah9FXMbJBCC"
      },
      "outputs": [],
      "source": [
        "def encode_text(tokens, vocab, is_add_sos = True, is_add_eos = True):\n",
        "    encoded = []\n",
        "    for w in tokens:\n",
        "        encoded.append(vocab.get(w, UNK_ID))\n",
        "\n",
        "    if is_add_sos:\n",
        "        encoded = [SOS_ID] + encoded\n",
        "    if is_add_eos:\n",
        "        encoded =  encoded + [EOS_ID]\n",
        "    return encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R7K2ytdJBCC"
      },
      "outputs": [],
      "source": [
        "train_df['en_encoded'] = train_df.en_tokens.apply(lambda x: encode_text(x, en_vocab))\n",
        "train_df['de_encoded'] = train_df.de_tokens.apply(lambda x: encode_text(x, de_vocab))\n",
        "\n",
        "## val\n",
        "val_df['en_encoded'] = val_df.en_tokens.apply(lambda x: encode_text(x, en_vocab))\n",
        "val_df['de_encoded'] = val_df.de_tokens.apply(lambda x: encode_text(x, de_vocab))\n",
        "## test\n",
        "test_df['en_encoded'] = test_df.en_tokens.apply(lambda x: encode_text(x, en_vocab))\n",
        "test_df['de_encoded'] = test_df.de_tokens.apply(lambda x: encode_text(x, de_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jCfHKiDJBCC",
        "outputId": "a5f55f6c-b7ec-4374-98b8-7c38f05167b0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>de</th>\n",
              "      <th>en_tokens</th>\n",
              "      <th>de_tokens</th>\n",
              "      <th>en_encoded</th>\n",
              "      <th>de_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two young, White males are outside near many b...</td>\n",
              "      <td>Zwei junge weiße Männer sind im Freien in der ...</td>\n",
              "      <td>[two, young, ,, white, males, are, outside, ne...</td>\n",
              "      <td>[zwei, junge, weiße, männer, sind, im, freien,...</td>\n",
              "      <td>[2, 7299, 1325, 8398, 4755, 226, 577, 8701, 14...</td>\n",
              "      <td>[2, 1495, 6694, 9780, 1638, 8224, 4642, 16038,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Several men in hard hats are operating a giant...</td>\n",
              "      <td>Mehrere Männer mit Schutzhelmen bedienen ein A...</td>\n",
              "      <td>[several, men, in, hard, hats, are, operating,...</td>\n",
              "      <td>[mehrere, männer, mit, schutzhelmen, bedienen,...</td>\n",
              "      <td>[2, 950, 8255, 5210, 230, 1048, 577, 6942, 379...</td>\n",
              "      <td>[2, 14004, 1638, 5708, 3788, 1417, 9361, 911, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A little girl climbing into a wooden playhouse.</td>\n",
              "      <td>Ein kleines Mädchen klettert in ein Spielhaus ...</td>\n",
              "      <td>[a, little, girl, climbing, into, a, wooden, p...</td>\n",
              "      <td>[ein, kleines, mädchen, klettert, in, ein, spi...</td>\n",
              "      <td>[2, 3791, 1317, 4398, 6125, 1165, 3791, 7154, ...</td>\n",
              "      <td>[2, 9361, 12382, 11351, 7168, 10069, 9361, 114...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en  \\\n",
              "0  Two young, White males are outside near many b...   \n",
              "1  Several men in hard hats are operating a giant...   \n",
              "2    A little girl climbing into a wooden playhouse.   \n",
              "\n",
              "                                                  de  \\\n",
              "0  Zwei junge weiße Männer sind im Freien in der ...   \n",
              "1  Mehrere Männer mit Schutzhelmen bedienen ein A...   \n",
              "2  Ein kleines Mädchen klettert in ein Spielhaus ...   \n",
              "\n",
              "                                           en_tokens  \\\n",
              "0  [two, young, ,, white, males, are, outside, ne...   \n",
              "1  [several, men, in, hard, hats, are, operating,...   \n",
              "2  [a, little, girl, climbing, into, a, wooden, p...   \n",
              "\n",
              "                                           de_tokens  \\\n",
              "0  [zwei, junge, weiße, männer, sind, im, freien,...   \n",
              "1  [mehrere, männer, mit, schutzhelmen, bedienen,...   \n",
              "2  [ein, kleines, mädchen, klettert, in, ein, spi...   \n",
              "\n",
              "                                          en_encoded  \\\n",
              "0  [2, 7299, 1325, 8398, 4755, 226, 577, 8701, 14...   \n",
              "1  [2, 950, 8255, 5210, 230, 1048, 577, 6942, 379...   \n",
              "2  [2, 3791, 1317, 4398, 6125, 1165, 3791, 7154, ...   \n",
              "\n",
              "                                          de_encoded  \n",
              "0  [2, 1495, 6694, 9780, 1638, 8224, 4642, 16038,...  \n",
              "1  [2, 14004, 1638, 5708, 3788, 1417, 9361, 911, ...  \n",
              "2  [2, 9361, 12382, 11351, 7168, 10069, 9361, 114...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMrhnBkHJBCC"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC6C4JC1JBCD"
      },
      "outputs": [],
      "source": [
        "train_data = train_df[['en_encoded','de_encoded']].to_dict('records')\n",
        "val_data = val_df[['en_encoded','de_encoded']].to_dict('records')\n",
        "test_data = test_df[['en_encoded','de_encoded']].to_dict('records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zW3w1wpJBCD",
        "outputId": "122792d9-8298-4124-ccad-8ffeba087f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'de_encoded': [2, 1495, 6694, 9780, 1638, 8224, 4642, 16038, 10069, 4241,\n",
            "                 15608, 4777, 13707, 901, 3],\n",
            "  'en_encoded': [2, 7299, 1325, 8398, 4755, 226, 577, 8701, 1462, 3851, 6981,\n",
            "                 483, 3]},\n",
            " {'de_encoded': [2, 14004, 1638, 5708, 3788, 1417, 9361, 911, 901, 3],\n",
            "  'en_encoded': [2, 950, 8255, 5210, 230, 1048, 577, 6942, 3791, 4323, 8692,\n",
            "                 2792, 483, 3]}]\n"
          ]
        }
      ],
      "source": [
        "pprint(train_data[:2], compact=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Et5DJeK1JBCD"
      },
      "outputs": [],
      "source": [
        "def custom_collate(batch):\n",
        "    \"\"\"\n",
        "    Dynamic padding : find the max len in the batch and do the padding\n",
        "    \"\"\"\n",
        "    en_batch = [torch.tensor(item['en_encoded']) for item in batch]\n",
        "    de_batch = [torch.tensor(item['de_encoded']) for item in batch]\n",
        "\n",
        "    padded_en = nn.utils.rnn.pad_sequence(en_batch, batch_first= True, padding_value= PAD_ID)\n",
        "    padded_de = nn.utils.rnn.pad_sequence(de_batch, batch_first= True, padding_value= PAD_ID)\n",
        "\n",
        "    return {\"padded_en\": padded_en, \"padded_de\":  padded_de}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuifcyP7JBCD",
        "outputId": "83cdfd9e-14e7-4cf9-96bd-9a940d9c11c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 14]) torch.Size([3, 15])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 3\n",
        "train_dl = DataLoader(train_data , batch_size = batch_size, shuffle = False, collate_fn= custom_collate)\n",
        "example = next(iter(train_dl))\n",
        "padded_en, padded_de = example['padded_en'],example['padded_de']\n",
        "print(padded_en.shape, padded_de.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySdroKTIJBCD",
        "outputId": "1710bd4b-ea19-4897-c7a7-6fe41857b822"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[   2, 7299, 1325, 8398, 4755,  226,  577, 8701, 1462, 3851, 6981,  483,\n",
              "            3,    1],\n",
              "        [   2,  950, 8255, 5210,  230, 1048,  577, 6942, 3791, 4323, 8692, 2792,\n",
              "          483,    3],\n",
              "        [   2, 3791, 1317, 4398, 6125, 1165, 3791, 7154, 3533,  483,    3,    1,\n",
              "            1,    1]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e_R2jq1JBCD",
        "outputId": "5123fea0-a79f-4971-9de3-51fecb9c5316"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[    2,  1495,  6694,  9780,  1638,  8224,  4642, 16038, 10069,  4241,\n",
              "         15608,  4777, 13707,   901,     3],\n",
              "        [    2, 14004,  1638,  5708,  3788,  1417,  9361,   911,   901,     3,\n",
              "             1,     1,     1,     1,     1],\n",
              "        [    2,  9361, 12382, 11351,  7168, 10069,  9361, 11478,  7174,   980,\n",
              "           901,     3,     1,     1,     1]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_de"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v721uyt6JBCD"
      },
      "outputs": [],
      "source": [
        "## dataloaders\n",
        "batch_size = 256\n",
        "train_dl = DataLoader(train_data , batch_size = batch_size, shuffle = True, collate_fn= custom_collate)\n",
        "val_dl = DataLoader(val_data , batch_size = batch_size, shuffle = False, collate_fn= custom_collate)\n",
        "test_dl = DataLoader(test_data , batch_size = batch_size, shuffle = False, collate_fn= custom_collate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xCS5zOgJBCE"
      },
      "source": [
        "## Building Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpCYQwnSJBCE"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Encode German text\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout, batch_first= True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        # batch = [batch size, sent len]\n",
        "        embedded = self.dropout(self.embedding(batch))\n",
        "        # embedded = [batch size, sent len, embedding dim]\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        # outputs = [batch size, sent len, hidden dim * n directions]\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        # outputs are always from the top hidden layer\n",
        "        return hidden, cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35uOcX2RJBCE",
        "outputId": "8a3708ab-8e68-4e03-a98e-758b5984c385"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : torch.Size([3, 15])\n",
            "torch.Size([2, 3, 64]) torch.Size([2, 3, 64])\n"
          ]
        }
      ],
      "source": [
        "## Enoder\n",
        "print(f\"Input : {padded_de.shape}\")\n",
        "encoder = Encoder(vocab_size = len(de_vocab), emb_dim = 100, hidden_dim=64, n_layers=2, dropout=0.1)\n",
        "hidden, cell = encoder(padded_de)\n",
        "print(hidden.shape, cell.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHkg6wZ1JBCE"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout,  batch_first= True)\n",
        "        self.fc_out = nn.Linear(hidden_dim, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        # input = [batch size]\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        # n directions in the decoder will both always be 1, therefore:\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        # context = [n layers, batch size, hidden dim]\n",
        "        input = input.unsqueeze(1)\n",
        "        # input = [batch size, 1]\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # print(embedded.shape)\n",
        "        # embedded = [batch size, 1, embedding dim]\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        # print(output.shape)\n",
        "        # print(hidden.shape)\n",
        "        # output = [batch size, seq length, hidden dim * n directions]\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        # seq length and n directions will always be 1 in this decoder, therefore:\n",
        "        # output = [batch size,1,hidden dim]\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        # cell = [n layers, batch size, hidden dim]\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        # prediction = [batch size, output dim]\n",
        "        return prediction, hidden, cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW-fifsAJBCE",
        "outputId": "b81638b2-6baa-44f1-c39f-b8094b945da3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Hidden : torch.Size([2, 3, 64])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 1, 9795]), torch.Size([2, 3, 64]), torch.Size([2, 3, 64]))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Decoder\n",
        "## de[:,0] -> first input\n",
        "print(f\"Input Hidden : {hidden.shape}\")\n",
        "decoder = Decoder(vocab_size = len(en_vocab), emb_dim = 100, hidden_dim=64, n_layers=2, dropout=0.1)\n",
        "prediction, hidden, cell = decoder(padded_en[:,0], hidden, cell)\n",
        "prediction.shape, hidden.shape, cell.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YB2I7c2CJBCE"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio):\n",
        "        # src = [batch size, sent len]\n",
        "        # trg = [batch size, sent len]\n",
        "        # teacher_forcing_ratio is probability to use teacher forcing\n",
        "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_length = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.vocab_size\n",
        "        # tensor to store decoder outputs\n",
        "        outputs = torch.zeros(batch_size,trg_length,trg_vocab_size).to(self.device)\n",
        "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        # first input to the decoder is the <sos> tokens\n",
        "        input = trg[:,0]\n",
        "        # input = [batch size]\n",
        "        for t in range(1, trg_length):\n",
        "            # insert input token embedding, previous hidden and previous cell states\n",
        "            # receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            # output = [batch size, output dim]\n",
        "            # hidden = [n layers, batch size, hidden dim]\n",
        "            # cell = [n layers, batch size, hidden dim]\n",
        "            # place predictions in a tensor holding predictions for each token\n",
        "            output = output.squeeze(dim = 1)\n",
        "            outputs[:,t,:] = output\n",
        "            # decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            # get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1)\n",
        "            # if teacher forcing, use actual next token as next input\n",
        "            # if not, use predicted token\n",
        "            input = trg[:,t] if teacher_force else top1\n",
        "            # input = [batch size]\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sn5PEEliJBCF",
        "outputId": "d37fa66b-8499-479d-b98d-0ebbf14900be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 14, 9795])\n"
          ]
        }
      ],
      "source": [
        "model = Seq2Seq(encoder, decoder, device = \"cpu\")\n",
        "outputs = model(padded_de, padded_en, teacher_forcing_ratio = True)\n",
        "print(outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6jgrXHaJBCF"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9dB2y-FJBCF"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqLightningModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, encode, decoder, learning_rate, device, teacher_forcing_ratio):\n",
        "        super().__init__()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.seq2seq_model = Seq2Seq(self.encoder, self.decoder, device)\n",
        "        self.loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
        "        self.init_weights()\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "        self.test_loss = []\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.named_parameters():\n",
        "            nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "    def forward(self, de, en):\n",
        "        logits = self.seq2seq_model(de, en, teacher_forcing_ratio = self.teacher_forcing_ratio)\n",
        "        return logits\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        src, trg = batch['padded_de'], batch['padded_en']\n",
        "        output = self(src, trg)\n",
        "        # output = [trg length, batch size, trg vocab size]\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
        "        trg = trg[1:].view(-1)\n",
        "        # trg = [(trg length - 1) * batch size]\n",
        "        # print(output.shape, trg.shape)\n",
        "        loss = self.loss_fn(output, trg)\n",
        "        self.train_loss.append(loss.item())\n",
        "        self.log_dict({\"train_loss\": loss}, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        src, trg = batch['padded_de'], batch['padded_en']\n",
        "        output = self(src, trg)\n",
        "        # output = [trg length, batch size, trg vocab size]\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
        "        trg = trg[1:].view(-1)\n",
        "        # trg = [(trg length - 1) * batch size]\n",
        "        loss = self.loss_fn(output, trg)\n",
        "        self.val_loss.append(loss.item())\n",
        "        self.log_dict({\"val_loss\": loss}, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        print(f\"Epoch : {self.current_epoch}  \\\n",
        "              Train Loss : {np.mean(self.train_loss)} \\\n",
        "              Val Loss : {np.mean(self.val_loss)} \\\n",
        "              Train PPL : {np.exp(np.mean(self.train_loss))} \\\n",
        "              Val PPL : {np.exp(np.mean(self.val_loss))} \")\n",
        "\n",
        "        self.train_loss =[]\n",
        "        self.val_loss =[]\n",
        "\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        src, trg = batch['padded_de'], batch['padded_en']\n",
        "        output = self(src, trg)\n",
        "        # output = [trg length, batch size, trg vocab size]\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
        "        trg = trg[1:].view(-1)\n",
        "        # trg = [(trg length - 1) * batch size]\n",
        "        loss = self.loss_fn(output, trg)\n",
        "        self.test_loss.append(loss.item())\n",
        "        return loss\n",
        "\n",
        "    def on_test_epoch_end(self) -> None:\n",
        "        print(f\"Test Loss : {np.mean(self.test_loss)}  Test PPL : {np.exp(np.mean(self.test_loss))}\")\n",
        "        self.test_loss = []\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt = optim.Adam(self.parameters(), lr = self.learning_rate)\n",
        "        return opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQPiKDamJBCF",
        "outputId": "8726bfd1-b750-45c1-c47a-86e3be30bdad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 14, 9795])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## test architecture\n",
        "encoder = Encoder(vocab_size = len(de_vocab), emb_dim = 256, hidden_dim=512, n_layers=2, dropout=0.5)\n",
        "decoder = Decoder(vocab_size = len(en_vocab), emb_dim = 256, hidden_dim=512, n_layers=2, dropout=0.5)\n",
        "model = Seq2SeqLightningModel(encoder, decoder, learning_rate= .001, device =\"cpu\", teacher_forcing_ratio=0.5)\n",
        "outputs = model(padded_de, padded_en)\n",
        "outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRSpZ1PrJBCG",
        "outputId": "0ea67514-4084-4df5-f3dd-482800ea4711",
        "colab": {
          "referenced_widgets": [
            "ebab98ff8bd24e7da69e537157397681",
            "511dc5815c244318922204fd8e7466a1",
            "8c8f6ae438fe40989eaaf69d300394ee",
            "0c49cb668c324020820f67f28c610881",
            "fd4a814136994cc4a907713829fb0c49",
            "d30f5e03da254a7e8838c007c5163b6f",
            "252ddbda4a6d4ca08177ba5b63583007"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
            "\n",
            "  | Name          | Type             | Params\n",
            "---------------------------------------------------\n",
            "0 | encoder       | Encoder          | 9.4 M \n",
            "1 | decoder       | Decoder          | 11.7 M\n",
            "2 | seq2seq_model | Seq2Seq          | 21.1 M\n",
            "3 | loss_fn       | CrossEntropyLoss | 0     \n",
            "---------------------------------------------------\n",
            "21.1 M    Trainable params\n",
            "0         Non-trainable params\n",
            "21.1 M    Total params\n",
            "84.403    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebab98ff8bd24e7da69e537157397681",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 0                Train Loss : nan               Val Loss : 9.208253860473633               Train PPL : nan               Val PPL : 9979.156637494161 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "511dc5815c244318922204fd8e7466a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c8f6ae438fe40989eaaf69d300394ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 1                Train Loss : 5.398061848523324               Val Loss : 4.96839964389801               Train PPL : 220.97771261212498               Val PPL : 143.79657740100245 \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c49cb668c324020820f67f28c610881",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 3                Train Loss : 4.736137818871883               Val Loss : 4.556632995605469               Train PPL : 113.99308844394642               Val PPL : 95.26219102736916 \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd4a814136994cc4a907713829fb0c49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 5                Train Loss : 4.391880961886623               Val Loss : 4.311069369316101               Train PPL : 80.79224327819627               Val PPL : 74.5201358935077 \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d30f5e03da254a7e8838c007c5163b6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 7                Train Loss : 4.136077172923506               Val Loss : 4.281099438667297               Train PPL : 62.5569394323715               Val PPL : 72.31990761728878 \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "252ddbda4a6d4ca08177ba5b63583007",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 9                Train Loss : 3.896537664689516               Val Loss : 3.9535250663757324               Train PPL : 49.23169703261136               Val PPL : 52.11876550650696 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        }
      ],
      "source": [
        "## clear old checkpoints\n",
        "checkpoints_dir = \"checkpoints_logs\"\n",
        "if os.path.exists(checkpoints_dir):\n",
        "    shutil.rmtree(checkpoints_dir)\n",
        "\n",
        "\n",
        "## Model Training\n",
        "encoder = Encoder(vocab_size = len(de_vocab), emb_dim = 300, hidden_dim=512, n_layers=2, dropout=0.5)\n",
        "decoder = Decoder(vocab_size = len(en_vocab), emb_dim = 300, hidden_dim=512, n_layers=2, dropout=0.5)\n",
        "model = Seq2SeqLightningModel(encoder, decoder, learning_rate= .001, device =\"cuda\", teacher_forcing_ratio=0.5)\n",
        "\n",
        "callbacks = pl.callbacks.ModelCheckpoint(dirpath = checkpoints_dir,\n",
        "                                         filename = '{epoch}-{val_loss:.2f}',\n",
        "                                          mode = \"min\",\n",
        "                                          monitor = \"val_loss\",\n",
        "                                          save_last = True,\n",
        "                                          save_top_k=-1)\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(accelerator= \"gpu\",\n",
        "           max_epochs=10,\n",
        "           check_val_every_n_epoch = 2,\n",
        "           gradient_clip_val=1,\n",
        "           gradient_clip_algorithm=\"value\",\n",
        "           callbacks = [callbacks])\n",
        "\n",
        "trainer.fit(model, train_dl, val_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e82WBoeJJBCG",
        "outputId": "745dae8f-8352-4526-d97b-3416af306313",
        "colab": {
          "referenced_widgets": [
            "7da55117996b4d11a34b26bffea06f67"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7da55117996b4d11a34b26bffea06f67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss : 3.9531922936439514  Test PPL : 52.101424687968105\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## if test dataset has loss near around val loss that means we are not overfitting\n",
        "model = model.eval()\n",
        "trainer.test(model, dataloaders= test_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlhONpSyJBCG"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYAc3-CgJBCG"
      },
      "outputs": [],
      "source": [
        "en_vocab_lookup = {i:w for w,i in en_vocab.items()}\n",
        "\n",
        "def encode_tokens(tokens, vocab):\n",
        "    encoded = []\n",
        "    for w in tokens:\n",
        "        encoded.append(vocab.get(w, UNK_ID))\n",
        "    return encoded\n",
        "\n",
        "\n",
        "def decode_tokens(tokens, vocab_loopup):\n",
        "    decoded = []\n",
        "    for i in tokens:\n",
        "        if i == 2 or i==3:\n",
        "            continue\n",
        "        decoded.append(vocab_loopup.get(i))\n",
        "    return decoded\n",
        "\n",
        "\n",
        "def translate_sentence(sentence, model, en_nlp, de_nlp, en_vocab, de_vocab, sos_token, eos_token, device, lower = True, max_output_length=15):\n",
        "    ## model eval mode\n",
        "    model.eval()\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    ## encode german sent\n",
        "    sent = str(sentence).lower() if lower else sentence\n",
        "    tokens = [token.text for token in de_nlp.tokenizer(sent)]\n",
        "    tokens = [sos_token] + tokens + [eos_token]\n",
        "    ids = encode_tokens(tokens, de_vocab)\n",
        "\n",
        "    ## encoder input\n",
        "    tensor = torch.LongTensor(ids).unsqueeze(0).to(device)\n",
        "    tensor = tensor.to(device)\n",
        "\n",
        "    ## encoder\n",
        "    hidden, cell = model.encoder(tensor)\n",
        "\n",
        "    ## input to decoder <sos>\n",
        "    inputs = encode_tokens([sos_token], en_vocab)\n",
        "\n",
        "    for _ in range(max_output_length):\n",
        "        inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
        "        output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n",
        "        predicted_token = output.argmax(-1).item()\n",
        "        inputs.append(predicted_token)\n",
        "        if predicted_token == en_vocab[eos_token]:\n",
        "            break\n",
        "\n",
        "    tokens = decode_tokens(inputs, en_vocab_lookup)\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q12Ejhp8JBCG",
        "outputId": "3fbe00a8-67c5-460b-baf7-9391c7952a05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'the', '.', '.']\n"
          ]
        }
      ],
      "source": [
        "sent = \"Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.\"\n",
        "predictions = translate_sentence(sent, model, nlp_en, nlp_de, en_vocab, de_vocab, sos_token=\"<sos>\", eos_token=\"<eos>\", device = \"cuda\")\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTj3XFKhJBCH"
      },
      "source": [
        "## Blue Scroe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YylD2xKDJBCH"
      },
      "outputs": [],
      "source": [
        "bleu = evaluate.load(\"bleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmhF9riuJBCH",
        "outputId": "5dde4298-337a-48f9-cbbc-58a2dec3f098",
        "colab": {
          "referenced_widgets": [
            "5aacaccdddfd4730bd8123d62ac62ad8"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_7203/152345126.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  prediction_list = [translate_sentence(sent, model, nlp_en, nlp_de, en_vocab, de_vocab, sos_token=\"<sos>\", eos_token=\"<eos>\", device = \"cuda\") for sent in tqdm_notebook(test_df.de.values)]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5aacaccdddfd4730bd8123d62ac62ad8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prediction_list = []\n",
        "prediction_list = [translate_sentence(sent, model, nlp_en, nlp_de, en_vocab, de_vocab, sos_token=\"<sos>\", eos_token=\"<eos>\", device = \"cuda\") for sent in tqdm_notebook(test_df.de.values)]\n",
        "predictions = list(map(lambda x: \" \".join(x),prediction_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y58xqFtYJBCH",
        "outputId": "9d349c56-bf45-4b2b-f9ba-135b5a65ed16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a man in a blue shirt is standing on the . .',\n",
            " 'a baseball player is running in the air with a a in a . .']\n"
          ]
        }
      ],
      "source": [
        "pprint(predictions[:2], compact = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B1RKBoEJBCH",
        "outputId": "aa4e38d2-9d6c-4c13-f6bd-cbf6ac36fa3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A man in an orange hat starring at something.',\n",
            " 'A Boston Terrier is running on lush green grass in front of a white fence.']\n"
          ]
        }
      ],
      "source": [
        "references = test_df.en.tolist()\n",
        "pprint(references[:2], compact=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoYHC46DJBCH"
      },
      "outputs": [],
      "source": [
        "def get_tokenizer_fn(nlp, lower):\n",
        "    def tokenizer_fn(s):\n",
        "        tokens = [token.text for token in nlp.tokenizer(s)]\n",
        "        if lower:\n",
        "            tokens = [token.lower() for token in tokens]\n",
        "        return tokens\n",
        "\n",
        "    return tokenizer_fn\n",
        "\n",
        "tokenizer_fn = get_tokenizer_fn(nlp_en,  lower = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M0CbacaJBCH",
        "outputId": "240b0f16-539e-4847-d023-768d20a617b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bleu': 0.09111998058723653,\n",
              " 'precisions': [0.43838704291200536,\n",
              "  0.14647476771725268,\n",
              "  0.06063339346562437,\n",
              "  0.0253954110046781],\n",
              " 'brevity_penalty': 0.9137801221396356,\n",
              " 'length_ratio': 0.917292081482616,\n",
              " 'translation_length': 11978,\n",
              " 'reference_length': 13058}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = bleu.compute(predictions=predictions, references=references, tokenizer=tokenizer_fn)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kts7hiicJBCH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lighting",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}