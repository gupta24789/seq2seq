{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gupta24789/seq2seq/blob/main/seq2seq_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5FXM8HEuLN_"
      },
      "source": [
        "## Machine Translation :  German to English"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CDoQu5puLOB"
      },
      "outputs": [],
      "source": [
        "# !pip install evaluate\n",
        "# !python -m spacy download de_core_news_sm\n",
        "# !python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5tmYNCPuLOC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hW8b9TJDuLOC"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import random\n",
        "import itertools\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm , tqdm_notebook\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import evaluate\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pytorch_lightning as pl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wdH4_rHuLOC"
      },
      "source": [
        "## Set Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdf1lGHDuLOC"
      },
      "outputs": [],
      "source": [
        "seed = 121\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPDViMoMuLOC"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFpqk8DruLOC",
        "outputId": "7d37e2ae-ce83-411f-e51b-40979696b5ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((29000, 2), (1014, 2), (1000, 2))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"https://raw.githubusercontent.com/gupta24789/seq2seq/main/data/train.csv\")\n",
        "val_df = pd.read_csv(\"https://raw.githubusercontent.com/gupta24789/seq2seq/main/data/val.csv\")\n",
        "test_df = pd.read_csv(\"https://raw.githubusercontent.com/gupta24789/seq2seq/main/data/test.csv\")\n",
        "\n",
        "train_df.shape, val_df.shape, test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgtB3LGcuLOD",
        "outputId": "72863972-c3a1-436e-e7fd-bffa18e62510"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>de</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two young, White males are outside near many b...</td>\n",
              "      <td>Zwei junge weiße Männer sind im Freien in der ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Several men in hard hats are operating a giant...</td>\n",
              "      <td>Mehrere Männer mit Schutzhelmen bedienen ein A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A little girl climbing into a wooden playhouse.</td>\n",
              "      <td>Ein kleines Mädchen klettert in ein Spielhaus ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en  \\\n",
              "0  Two young, White males are outside near many b...   \n",
              "1  Several men in hard hats are operating a giant...   \n",
              "2    A little girl climbing into a wooden playhouse.   \n",
              "\n",
              "                                                  de  \n",
              "0  Zwei junge weiße Männer sind im Freien in der ...  \n",
              "1  Mehrere Männer mit Schutzhelmen bedienen ein A...  \n",
              "2  Ein kleines Mädchen klettert in ein Spielhaus ...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXkzRWG_uLOD"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faZXyU41uLOD"
      },
      "outputs": [],
      "source": [
        "en_nlp = spacy.load(\"en_core_web_sm\")\n",
        "de_nlp = spacy.load(\"de_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTr1D38ZuLOD",
        "outputId": "d09a0540-0244-450e-c764-7e86c8ba1263"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['What', 'a', 'lovely', 'day', 'it', 'is', 'today', '!']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "string = \"What a lovely day it is today!\"\n",
        "[token.text for token in en_nlp.tokenizer(string)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2cXKI1muLOD"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQSzVMaluLOE"
      },
      "outputs": [],
      "source": [
        "def tokenized_text(text, nlp, is_lower = True):\n",
        "    if is_lower:\n",
        "        text = str(text).lower()\n",
        "    tokens = [token.text for token in nlp.tokenizer(text)]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwY2lOO-uLOE"
      },
      "outputs": [],
      "source": [
        "## train\n",
        "train_df['en_tokens'] = train_df.en.map(lambda x: tokenized_text(x, en_nlp))\n",
        "train_df['de_tokens'] = train_df.de.map(lambda x: tokenized_text(x, de_nlp))\n",
        "## val\n",
        "val_df['en_tokens'] = val_df.en.map(lambda x: tokenized_text(x, en_nlp))\n",
        "val_df['de_tokens'] = val_df.de.map(lambda x: tokenized_text(x, de_nlp))\n",
        "## test\n",
        "test_df['en_tokens'] = test_df.en.map(lambda x: tokenized_text(x, en_nlp))\n",
        "test_df['de_tokens'] = test_df.de.map(lambda x: tokenized_text(x, de_nlp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB18UrXVuLOE",
        "outputId": "ee650e4d-cdc9-4992-fa5b-0dae978ea0c3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>de</th>\n",
              "      <th>en_tokens</th>\n",
              "      <th>de_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two young, White males are outside near many b...</td>\n",
              "      <td>Zwei junge weiße Männer sind im Freien in der ...</td>\n",
              "      <td>[two, young, ,, white, males, are, outside, ne...</td>\n",
              "      <td>[zwei, junge, weiße, männer, sind, im, freien,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Several men in hard hats are operating a giant...</td>\n",
              "      <td>Mehrere Männer mit Schutzhelmen bedienen ein A...</td>\n",
              "      <td>[several, men, in, hard, hats, are, operating,...</td>\n",
              "      <td>[mehrere, männer, mit, schutzhelmen, bedienen,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A little girl climbing into a wooden playhouse.</td>\n",
              "      <td>Ein kleines Mädchen klettert in ein Spielhaus ...</td>\n",
              "      <td>[a, little, girl, climbing, into, a, wooden, p...</td>\n",
              "      <td>[ein, kleines, mädchen, klettert, in, ein, spi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en  \\\n",
              "0  Two young, White males are outside near many b...   \n",
              "1  Several men in hard hats are operating a giant...   \n",
              "2    A little girl climbing into a wooden playhouse.   \n",
              "\n",
              "                                                  de  \\\n",
              "0  Zwei junge weiße Männer sind im Freien in der ...   \n",
              "1  Mehrere Männer mit Schutzhelmen bedienen ein A...   \n",
              "2  Ein kleines Mädchen klettert in ein Spielhaus ...   \n",
              "\n",
              "                                           en_tokens  \\\n",
              "0  [two, young, ,, white, males, are, outside, ne...   \n",
              "1  [several, men, in, hard, hats, are, operating,...   \n",
              "2  [a, little, girl, climbing, into, a, wooden, p...   \n",
              "\n",
              "                                           de_tokens  \n",
              "0  [zwei, junge, weiße, männer, sind, im, freien,...  \n",
              "1  [mehrere, männer, mit, schutzhelmen, bedienen,...  \n",
              "2  [ein, kleines, mädchen, klettert, in, ein, spi...  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5TtBsj6uLOE"
      },
      "source": [
        "## Build Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM6ToCa_uLOE",
        "outputId": "5dbd4d34-2b33-426a-f703-2af6bd129576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "en_vocab : 9795\n",
            "de_vocab : 18669\n"
          ]
        }
      ],
      "source": [
        "special_words = [\"<unk>\",\"<pad>\", \"<sos>\",\"<eos>\"]\n",
        "en_words = list(set(itertools.chain.from_iterable(train_df.en_tokens.tolist())))\n",
        "de_words = list(set(itertools.chain.from_iterable(train_df.de_tokens.tolist())))\n",
        "\n",
        "en_words = special_words + en_words\n",
        "de_words = special_words + de_words\n",
        "\n",
        "en_vocab = {w:i for i,w in enumerate(en_words)}\n",
        "de_vocab = {w:i for i,w in enumerate(de_words)}\n",
        "\n",
        "UNK_ID = en_vocab['<unk>']\n",
        "PAD_ID = en_vocab['<pad>']\n",
        "SOS_ID = en_vocab['<sos>']\n",
        "EOS_ID = en_vocab['<eos>']\n",
        "\n",
        "print(f\"en_vocab : {len(en_vocab)}\")\n",
        "print(f\"de_vocab : {len(de_vocab)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ60-earuLOE"
      },
      "source": [
        "## Encode text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybsJduCGuLOE"
      },
      "outputs": [],
      "source": [
        "def encode_tokens(tokens, vocab):\n",
        "    encoded = []\n",
        "    for w in tokens:\n",
        "        encoded.append(vocab.get(w, UNK_ID))\n",
        "    ## adding SOS & EOS\n",
        "    encoded = [SOS_ID] + encoded + [EOS_ID]\n",
        "    return encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2Mt0X6luLOE"
      },
      "outputs": [],
      "source": [
        "## train\n",
        "train_df['en_encoded'] = train_df.en_tokens.apply(lambda x: encode_tokens(x, en_vocab))\n",
        "train_df['de_encoded'] = train_df.de_tokens.apply(lambda x: encode_tokens(x, de_vocab))\n",
        "## val\n",
        "val_df['en_encoded'] = val_df.en_tokens.apply(lambda x: encode_tokens(x, en_vocab))\n",
        "val_df['de_encoded'] = val_df.de_tokens.apply(lambda x: encode_tokens(x, de_vocab))\n",
        "## test\n",
        "test_df['en_encoded'] = test_df.en_tokens.apply(lambda x: encode_tokens(x, en_vocab))\n",
        "test_df['de_encoded'] = test_df.de_tokens.apply(lambda x: encode_tokens(x, de_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZ137mAGuLOF",
        "outputId": "e5fdc66b-1400-4e04-fa56-abd76f8842b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>de</th>\n",
              "      <th>en_tokens</th>\n",
              "      <th>de_tokens</th>\n",
              "      <th>en_encoded</th>\n",
              "      <th>de_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two young, White males are outside near many b...</td>\n",
              "      <td>Zwei junge weiße Männer sind im Freien in der ...</td>\n",
              "      <td>[two, young, ,, white, males, are, outside, ne...</td>\n",
              "      <td>[zwei, junge, weiße, männer, sind, im, freien,...</td>\n",
              "      <td>[2, 5541, 9748, 8668, 7232, 8020, 7823, 8151, ...</td>\n",
              "      <td>[2, 2385, 11534, 14627, 3930, 14243, 13553, 53...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Several men in hard hats are operating a giant...</td>\n",
              "      <td>Mehrere Männer mit Schutzhelmen bedienen ein A...</td>\n",
              "      <td>[several, men, in, hard, hats, are, operating,...</td>\n",
              "      <td>[mehrere, männer, mit, schutzhelmen, bedienen,...</td>\n",
              "      <td>[2, 1284, 5992, 1851, 9535, 2874, 7823, 3462, ...</td>\n",
              "      <td>[2, 14301, 3930, 12728, 1589, 2399, 283, 6457,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A little girl climbing into a wooden playhouse.</td>\n",
              "      <td>Ein kleines Mädchen klettert in ein Spielhaus ...</td>\n",
              "      <td>[a, little, girl, climbing, into, a, wooden, p...</td>\n",
              "      <td>[ein, kleines, mädchen, klettert, in, ein, spi...</td>\n",
              "      <td>[2, 7839, 5797, 7125, 2508, 2498, 7839, 5052, ...</td>\n",
              "      <td>[2, 283, 5511, 2398, 11884, 3497, 283, 4337, 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en  \\\n",
              "0  Two young, White males are outside near many b...   \n",
              "1  Several men in hard hats are operating a giant...   \n",
              "2    A little girl climbing into a wooden playhouse.   \n",
              "\n",
              "                                                  de  \\\n",
              "0  Zwei junge weiße Männer sind im Freien in der ...   \n",
              "1  Mehrere Männer mit Schutzhelmen bedienen ein A...   \n",
              "2  Ein kleines Mädchen klettert in ein Spielhaus ...   \n",
              "\n",
              "                                           en_tokens  \\\n",
              "0  [two, young, ,, white, males, are, outside, ne...   \n",
              "1  [several, men, in, hard, hats, are, operating,...   \n",
              "2  [a, little, girl, climbing, into, a, wooden, p...   \n",
              "\n",
              "                                           de_tokens  \\\n",
              "0  [zwei, junge, weiße, männer, sind, im, freien,...   \n",
              "1  [mehrere, männer, mit, schutzhelmen, bedienen,...   \n",
              "2  [ein, kleines, mädchen, klettert, in, ein, spi...   \n",
              "\n",
              "                                          en_encoded  \\\n",
              "0  [2, 5541, 9748, 8668, 7232, 8020, 7823, 8151, ...   \n",
              "1  [2, 1284, 5992, 1851, 9535, 2874, 7823, 3462, ...   \n",
              "2  [2, 7839, 5797, 7125, 2508, 2498, 7839, 5052, ...   \n",
              "\n",
              "                                          de_encoded  \n",
              "0  [2, 2385, 11534, 14627, 3930, 14243, 13553, 53...  \n",
              "1  [2, 14301, 3930, 12728, 1589, 2399, 283, 6457,...  \n",
              "2  [2, 283, 5511, 2398, 11884, 3497, 283, 4337, 1...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKXdV351uLOF"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHBLkHTRuLOF"
      },
      "outputs": [],
      "source": [
        "train_data = train_df[['en_encoded','de_encoded']].to_dict('records')\n",
        "val_data = val_df[['en_encoded','de_encoded']].to_dict('records')\n",
        "test_data = test_df[['en_encoded','de_encoded']].to_dict('records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ogeadD9uLOF",
        "outputId": "2bb4dc00-f732-4b2f-f6b7-0ad459860392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'de_encoded': [2, 2385, 11534, 14627, 3930, 14243, 13553, 5325, 3497, 4550,\n",
            "                 5601, 4632, 8111, 5154, 3],\n",
            "  'en_encoded': [2, 5541, 9748, 8668, 7232, 8020, 7823, 8151, 3040, 1491, 6715,\n",
            "                 2734, 3]},\n",
            " {'de_encoded': [2, 14301, 3930, 12728, 1589, 2399, 283, 6457, 5154, 3],\n",
            "  'en_encoded': [2, 1284, 5992, 1851, 9535, 2874, 7823, 3462, 7839, 1938, 164,\n",
            "                 7192, 2734, 3]}]\n"
          ]
        }
      ],
      "source": [
        "pprint(train_data[:2], compact=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhRInc6ouLOF"
      },
      "outputs": [],
      "source": [
        "def custom_collate(batch):\n",
        "    \"\"\"\n",
        "    Dynamic padding : find the max len in the batch and do the padding\n",
        "    \"\"\"\n",
        "    en_batch = [torch.tensor(item['en_encoded']) for item in batch]\n",
        "    de_batch = [torch.tensor(item['de_encoded']) for item in batch]\n",
        "\n",
        "    padded_en = nn.utils.rnn.pad_sequence(en_batch, batch_first= True, padding_value= PAD_ID)\n",
        "    padded_de = nn.utils.rnn.pad_sequence(de_batch, batch_first= True, padding_value= PAD_ID)\n",
        "\n",
        "    return {\"padded_en\": padded_en, \"padded_de\":  padded_de}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0bvLGTPuLOF",
        "outputId": "c3df0ffa-6967-4c87-ec92-088fb33bd6c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 14]) torch.Size([3, 15])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 3\n",
        "train_dl = DataLoader(train_data , batch_size = batch_size, shuffle = False, collate_fn= custom_collate)\n",
        "example = next(iter(train_dl))\n",
        "padded_en, padded_de = example['padded_en'],example['padded_de']\n",
        "print(padded_en.shape, padded_de.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf4cO1nluLOF",
        "outputId": "4cf26d46-cc44-412b-8cb6-98d27fa33126"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[   2, 5541, 9748, 8668, 7232, 8020, 7823, 8151, 3040, 1491, 6715, 2734,\n",
              "            3,    1],\n",
              "        [   2, 1284, 5992, 1851, 9535, 2874, 7823, 3462, 7839, 1938,  164, 7192,\n",
              "         2734,    3],\n",
              "        [   2, 7839, 5797, 7125, 2508, 2498, 7839, 5052, 5598, 2734,    3,    1,\n",
              "            1,    1]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sp1orieauLOF",
        "outputId": "68c4b2db-c29a-417c-9dc5-c9ce6143eebe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[    2,  2385, 11534, 14627,  3930, 14243, 13553,  5325,  3497,  4550,\n",
              "          5601,  4632,  8111,  5154,     3],\n",
              "        [    2, 14301,  3930, 12728,  1589,  2399,   283,  6457,  5154,     3,\n",
              "             1,     1,     1,     1,     1],\n",
              "        [    2,   283,  5511,  2398, 11884,  3497,   283,  4337,  1523,  1491,\n",
              "          5154,     3,     1,     1,     1]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_de"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehbSe30IuLOF"
      },
      "outputs": [],
      "source": [
        "## dataloaders\n",
        "batch_size = 512\n",
        "train_dl = DataLoader(train_data , batch_size = batch_size, shuffle = True, collate_fn= custom_collate)\n",
        "val_dl = DataLoader(val_data , batch_size = batch_size, shuffle = False, collate_fn= custom_collate)\n",
        "test_dl = DataLoader(test_data , batch_size = batch_size, shuffle = False, collate_fn= custom_collate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqPAIOZkuLOG"
      },
      "source": [
        "## Building Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4C7JoRAluLOG"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Encode German text\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, emb_dim, encoder_hidden_dim, decoder_hidden_dim, dropout, n_layers, bidirectional):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, encoder_hidden_dim, dropout=dropout, num_layers = n_layers, bidirectional = bidirectional, batch_first= True)\n",
        "        self.linear = nn.Linear(encoder_hidden_dim * 2 if bidirectional else encoder_hidden_dim, decoder_hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, batch, verbose = False):\n",
        "        # batch : [batch size, sent len]\n",
        "        embedded = self.dropout(self.embedding(batch))\n",
        "        # embedded : [batch size, sent len , emb dim]\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        # output : [batch size, sent len, hidden dim * num directions]\n",
        "        # hidden : [n_layers * num directions, batch size, sent len]\n",
        "\n",
        "        # outputs are always from the last layer\n",
        "        # hidden [-2, :, : ] is the last of the forwards RNN\n",
        "        # hidden [-1, :, : ] is the last of the backwards RNN\n",
        "\n",
        "        combined_hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
        "        final_hidden = torch.tanh(self.linear(combined_hidden))\n",
        "\n",
        "        if verbose:\n",
        "            print(f'input : {batch.shape}')\n",
        "            print(f'embedded : {embedded.shape}')\n",
        "            print(f'output : {output.shape}')\n",
        "            print(f'hidden : {hidden.shape}')\n",
        "            print(f'combined_hidden : {combined_hidden.shape}')\n",
        "            print(f'final_hidden : {final_hidden.shape}')\n",
        "\n",
        "        return output, final_hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxigbFt1uLOG"
      },
      "outputs": [],
      "source": [
        "## Config\n",
        "encoder_bidirectional = True\n",
        "encoder_hidden_dim = 32\n",
        "decoder_hidden_dim = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Jgiw7QmuLOG",
        "outputId": "a806ea91-9eb9-4b9e-bca4-3891fec2a87a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input : torch.Size([3, 15])\n",
            "embedded : torch.Size([3, 15, 100])\n",
            "output : torch.Size([3, 15, 64])\n",
            "hidden : torch.Size([4, 3, 32])\n",
            "combined_hidden : torch.Size([3, 64])\n",
            "final_hidden : torch.Size([3, 128])\n"
          ]
        }
      ],
      "source": [
        "## Enoder\n",
        "encoder = Encoder(vocab_size = len(de_vocab), emb_dim = 100, encoder_hidden_dim=encoder_hidden_dim,\n",
        "                  decoder_hidden_dim = decoder_hidden_dim,\n",
        "                  dropout=0.1, n_layers= 2, bidirectional= encoder_bidirectional)\n",
        "output, hidden = encoder(padded_de, verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuzEDA50uLOG"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim, encoder_bidirectional):\n",
        "        super().__init__()\n",
        "        self.attn_fc = nn.Linear((encoder_hidden_dim * 2 if encoder_bidirectional else encoder_hidden_dim) + decoder_hidden_dim, decoder_hidden_dim)\n",
        "        self.v_fc = nn.Linear(decoder_hidden_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden = [batch size, decoder hidden dim]\n",
        "        # encoder_outputs = [batch size, src length, encoder hidden dim * encoder num direction]\n",
        "        batch_size, src_length = encoder_outputs.shape[0], encoder_outputs.shape[1]\n",
        "\n",
        "        # repeat decoder hidden state src_length times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_length, 1)\n",
        "        # hidden = [batch size, src length, decoder hidden dim]\n",
        "        # encoder_outputs = [batch size, src length, encoder hidden dim * encoder num direction]\n",
        "        energy = torch.tanh(self.attn_fc(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        # energy = [batch size, src length, decoder hidden dim]\n",
        "        attention = self.v_fc(energy).squeeze(2)\n",
        "        # attention = [batch size, src length]\n",
        "        return torch.softmax(attention, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sc0YQsfTuLOG"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, encoder_hidden_dim,decoder_hidden_dim, dropout, attention, encoder_bidirectional):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.GRU((encoder_hidden_dim * 2 if encoder_bidirectional else encoder_hidden_dim) + emb_dim, decoder_hidden_dim, dropout=dropout, batch_first= True)\n",
        "        self.fc_out = nn.Linear((encoder_hidden_dim * 2 if encoder_bidirectional else encoder_hidden_dim) + decoder_hidden_dim + emb_dim, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "\n",
        "        # input = [batch size]\n",
        "        # hidden = [batch size, decoder hidden dim]\n",
        "        # encoder_outputs = [batch size, src length, encoder hidden dim * encoder num direction]\n",
        "        # print(f'hidden : {hidden.shape}')\n",
        "        # print(f'encoder_outputs : {encoder_outputs.shape}')\n",
        "\n",
        "        input = input.unsqueeze(1)\n",
        "        # input = [batch size, 1]\n",
        "        # print(f'input : {input.shape}')\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded = [batch size, 1, embedding dim]\n",
        "        # print(f'embedded : {embedded.shape}')\n",
        "\n",
        "        a = self.attention(hidden, encoder_outputs)\n",
        "        # a = [batch size, src length]\n",
        "        a = a.unsqueeze(dim = 1)\n",
        "        # a = [batch size, 1, src length]\n",
        "        # print(f'a : {a.shape}')\n",
        "\n",
        "\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        # weighted = [batch size, 1, encoder hidden dim * encoder n_direction]\n",
        "        # print(f'weighted : {weighted.shape}')\n",
        "\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
        "        # rnn_input = [batch size, 1, (encoder hidden dim * encoder n_direction) + embedding dim]\n",
        "        # print(f'rnn_input : {rnn_input.shape}')\n",
        "\n",
        "\n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        # output = [seq length, batch size, decoder hid dim * n directions]\n",
        "        # hidden = [n layers * n directions, batch size, decoder hid dim]\n",
        "        # seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        # output = [1, batch size, decoder hidden dim]\n",
        "        # hidden = [1, batch size, decoder hidden dim]\n",
        "        # this also means that output == hidden\n",
        "\n",
        "        # print(f'output : {output.shape}')\n",
        "        # print(f'hidden : {hidden.shape}')\n",
        "\n",
        "        embedded = embedded.squeeze(1)\n",
        "        output = output.squeeze(1)\n",
        "        weighted = weighted.squeeze(1)\n",
        "\n",
        "        # print(f'embedded : {embedded.shape}')\n",
        "        # print(f'weighted : {weighted.shape}')\n",
        "        # print(f'output : {output.shape}')\n",
        "\n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
        "        # prediction = [batch size, output dim]\n",
        "        # print(f'prediction : {prediction.shape}')\n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lG-nc2fuLOH",
        "outputId": "51279059-e167-4545-8e65-c7fb153e0a27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 9795]) torch.Size([3, 128]) torch.Size([3, 15])\n"
          ]
        }
      ],
      "source": [
        "## Decoder\n",
        "## de[:,0] -> first input\n",
        "attention = Attention(encoder_hidden_dim, decoder_hidden_dim, encoder_bidirectional = encoder_bidirectional)\n",
        "decoder = Decoder(vocab_size = len(en_vocab),\n",
        "                  emb_dim = 100,\n",
        "                  encoder_hidden_dim = encoder_hidden_dim,\n",
        "                  decoder_hidden_dim = decoder_hidden_dim,\n",
        "                  dropout = 0.1,\n",
        "                  attention = attention,\n",
        "                  encoder_bidirectional = encoder_bidirectional)\n",
        "prediction, hidden, a = decoder(padded_en[:,0], hidden, output)\n",
        "print(prediction.shape, hidden.shape, a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MeI9nQNuLOH"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio):\n",
        "        # src = [batch size, sent len]\n",
        "        # trg = [batch size, sent len]\n",
        "        # teacher_forcing_ratio is probability to use teacher forcing\n",
        "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_length = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.vocab_size\n",
        "        # tensor to store decoder outputs\n",
        "        outputs = torch.zeros(batch_size,trg_length,trg_vocab_size).to(self.device)\n",
        "        # encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        # hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "        # outputs = [src length, batch size, encoder hidden dim * 2]\n",
        "        # hidden = [batch size, decoder hidden dim]\n",
        "        # first input to the decoder is the <sos> tokens\n",
        "        input = trg[:,0]\n",
        "        # input = [batch size]\n",
        "        for t in range(1, trg_length):\n",
        "            # insert input token embedding, previous hidden and previous cell states\n",
        "            # receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs)\n",
        "            # output = [batch size, output dim]\n",
        "            # hidden = [n layers, batch size, decoder hidden dim]\n",
        "            # place predictions in a tensor holding predictions for each token\n",
        "            output = output.squeeze(dim = 1)\n",
        "            outputs[:,t,:] = output\n",
        "            # decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            # get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1)\n",
        "            # if teacher forcing, use actual next token as next input\n",
        "            # if not, use predicted token\n",
        "            input = trg[:,t] if teacher_force else top1\n",
        "            # input = [batch size]\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy6gnnJbuLOH",
        "outputId": "b6944f69-e323-4e42-a7eb-524225504c0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 14, 9795])\n"
          ]
        }
      ],
      "source": [
        "model = Seq2Seq(encoder, decoder, device = \"cpu\")\n",
        "outputs = model(padded_de, padded_en, teacher_forcing_ratio = True)\n",
        "print(outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVcIacAEuLOH"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rV6j52WruLOH"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqLightningModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, encode, decoder, learning_rate, device, teacher_forcing_ratio):\n",
        "        super().__init__()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.seq2seq_model = Seq2Seq(self.encoder, self.decoder, device)\n",
        "        self.loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
        "        self.init_weights()\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "        self.test_loss = []\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.named_parameters():\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "\n",
        "    def forward(self, de, en):\n",
        "        logits = self.seq2seq_model(de, en, teacher_forcing_ratio = self.teacher_forcing_ratio)\n",
        "        return logits\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        src, trg = batch['padded_de'], batch['padded_en']\n",
        "        output = self(src, trg)\n",
        "        # output = [trg length, batch size, trg vocab size]\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
        "        trg = trg[1:].view(-1)\n",
        "        # trg = [(trg length - 1) * batch size]\n",
        "        # print(output.shape, trg.shape)\n",
        "        loss = self.loss_fn(output, trg)\n",
        "        self.train_loss.append(loss.item())\n",
        "        self.log_dict({\"train_loss\": loss}, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        src, trg = batch['padded_de'], batch['padded_en']\n",
        "        output = self(src, trg)\n",
        "        # output = [trg length, batch size, trg vocab size]\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
        "        trg = trg[1:].view(-1)\n",
        "        # trg = [(trg length - 1) * batch size]\n",
        "        loss = self.loss_fn(output, trg)\n",
        "        self.val_loss.append(loss.item())\n",
        "        self.log_dict({\"val_loss\": loss}, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        print(f\"Epoch : {self.current_epoch}  \\\n",
        "              Train Loss : {np.mean(self.train_loss)} \\\n",
        "              Val Loss : {np.mean(self.val_loss)} \\\n",
        "              Train PPL : {np.exp(np.mean(self.train_loss))} \\\n",
        "              Val PPL : {np.exp(np.mean(self.val_loss))} \")\n",
        "\n",
        "        self.train_loss =[]\n",
        "        self.val_loss =[]\n",
        "\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        src, trg = batch['padded_de'], batch['padded_en']\n",
        "        output = self(src, trg)\n",
        "        # output = [trg length, batch size, trg vocab size]\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
        "        trg = trg[1:].view(-1)\n",
        "        # trg = [(trg length - 1) * batch size]\n",
        "        loss = self.loss_fn(output, trg)\n",
        "        self.test_loss.append(loss.item())\n",
        "        return loss\n",
        "\n",
        "    def on_test_epoch_end(self) -> None:\n",
        "        print(f\"Test Loss : {np.mean(self.test_loss)}  Test PPL : {np.exp(np.mean(self.test_loss))}\")\n",
        "        self.test_loss = []\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt = optim.Adam(self.parameters(), lr = self.learning_rate)\n",
        "        return opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wYVltPduLOI"
      },
      "outputs": [],
      "source": [
        "# ## test architecture\n",
        "# encoder = Encoder(vocab_size = len(de_vocab), emb_dim = 100, encoder_hidden_dim=encoder_hidden_dim,\n",
        "#                   decoder_hidden_dim = decoder_hidden_dim,\n",
        "#                   dropout=0.1, n_layers= 2, bidirectional= encoder_bidirectional)\n",
        "# attention = Attention(encoder_hidden_dim, decoder_hidden_dim, encoder_bidirectional = encoder_bidirectional)\n",
        "# decoder = Decoder(vocab_size = len(en_vocab),\n",
        "#                   emb_dim = 100,\n",
        "#                   encoder_hidden_dim = encoder_hidden_dim,\n",
        "#                   decoder_hidden_dim = decoder_hidden_dim,\n",
        "#                   dropout = 0.1,\n",
        "#                   attention = attention,\n",
        "#                   encoder_bidirectional = encoder_bidirectional)\n",
        "# model = Seq2SeqLightningModel(encoder, decoder, learning_rate= .001, device =\"cpu\", teacher_forcing_ratio=0.5)\n",
        "# outputs = model(padded_de, padded_en)\n",
        "# outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ygtw9oafuLOI",
        "outputId": "da7a5f0f-92f3-4290-e2e1-9e02a8a13e1c",
        "colab": {
          "referenced_widgets": [
            "32b65c7af44940f08a638fa6e21c46be",
            "bb246f96ee594527ad85c4c13034ba09",
            "1ef6b82895b946ca9192df65800a42ed",
            "511f89baeb26497387b6621d5d94f8ce",
            "2bc00a63b5a247e18092208219047dcc",
            "43b1d59bf05c4365987f9c1f756eeeab",
            "ab529cddb9294737a529689eb83adf2d"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
            "\n",
            "  | Name          | Type             | Params\n",
            "---------------------------------------------------\n",
            "0 | encoder       | Encoder          | 12.4 M\n",
            "1 | decoder       | Decoder          | 23.6 M\n",
            "2 | seq2seq_model | Seq2Seq          | 36.0 M\n",
            "3 | loss_fn       | CrossEntropyLoss | 0     \n",
            "---------------------------------------------------\n",
            "36.0 M    Trainable params\n",
            "0         Non-trainable params\n",
            "36.0 M    Total params\n",
            "144.029   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32b65c7af44940f08a638fa6e21c46be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 0                Train Loss : nan               Val Loss : 9.1892991065979               Train PPL : nan               Val PPL : 9791.785575621763 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb246f96ee594527ad85c4c13034ba09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ef6b82895b946ca9192df65800a42ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 1                Train Loss : 5.5035089317121               Val Loss : 4.889101982116699               Train PPL : 245.55204770569037               Val PPL : 132.83423295737433 \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "511f89baeb26497387b6621d5d94f8ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 3                Train Loss : 4.601984998636079               Val Loss : 4.404259443283081               Train PPL : 99.68198799756638               Val PPL : 81.7985439463234 \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bc00a63b5a247e18092208219047dcc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 5                Train Loss : 4.148892768642359               Val Loss : 4.072455883026123               Train PPL : 63.363803053319536               Val PPL : 58.7009483761357 \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43b1d59bf05c4365987f9c1f756eeeab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 7                Train Loss : 3.595691781294973               Val Loss : 3.7953226566314697               Train PPL : 36.44090040355712               Val PPL : 44.49258991896468 \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab529cddb9294737a529689eb83adf2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 9                Train Loss : 3.042349675245452               Val Loss : 3.8322120904922485               Train PPL : 20.954421521497498               Val PPL : 46.16454552016852 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        }
      ],
      "source": [
        "## clear old checkpoints\n",
        "checkpoints_dir = \"checkpoints_logs\"\n",
        "if os.path.exists(checkpoints_dir):\n",
        "    shutil.rmtree(checkpoints_dir)\n",
        "\n",
        "## CONFIG\n",
        "n_layers = 2\n",
        "encoder_bidirectional = True\n",
        "encoder_emb_dim = 256\n",
        "decoder_emb_dim = 256\n",
        "encoder_hidden_dim = 512\n",
        "decoder_hidden_dim = 512\n",
        "encoder_dropout = 0.5\n",
        "decoder_dropout = 0.5\n",
        "\n",
        "\n",
        "## Model Training\n",
        "encoder = Encoder(vocab_size = len(de_vocab),\n",
        "                  emb_dim = encoder_emb_dim,\n",
        "                  encoder_hidden_dim=encoder_hidden_dim,\n",
        "                  decoder_hidden_dim = decoder_hidden_dim,\n",
        "                  dropout=0.1,\n",
        "                  n_layers= 2,\n",
        "                  bidirectional= encoder_bidirectional)\n",
        "\n",
        "attention = Attention(encoder_hidden_dim, decoder_hidden_dim, encoder_bidirectional = encoder_bidirectional)\n",
        "\n",
        "decoder = Decoder(vocab_size = len(en_vocab),\n",
        "                  emb_dim = decoder_emb_dim,\n",
        "                  encoder_hidden_dim = encoder_hidden_dim,\n",
        "                  decoder_hidden_dim = decoder_hidden_dim,\n",
        "                  dropout = 0.1,\n",
        "                  attention = attention,\n",
        "                  encoder_bidirectional = encoder_bidirectional)\n",
        "model = Seq2SeqLightningModel(encoder, decoder, learning_rate= .001, device =\"cuda\", teacher_forcing_ratio=0.5)\n",
        "\n",
        "callbacks = pl.callbacks.ModelCheckpoint(dirpath = checkpoints_dir,\n",
        "                                         filename = '{epoch}-{val_loss:.2f}',\n",
        "                                          mode = \"min\",\n",
        "                                          monitor = \"val_loss\",\n",
        "                                          save_last = True,\n",
        "                                          save_top_k=-1)\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(accelerator= \"gpu\",\n",
        "           max_epochs=10,\n",
        "           check_val_every_n_epoch = 2,\n",
        "           gradient_clip_val=1,\n",
        "           gradient_clip_algorithm=\"value\",\n",
        "           callbacks = [callbacks])\n",
        "\n",
        "trainer.fit(model, train_dl, val_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp0BQlA-uLOI",
        "outputId": "fea4b2d6-7e6b-403c-88fc-b4d0dd358052",
        "colab": {
          "referenced_widgets": [
            "2a61780536284616a287d1358984fc1b"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a61780536284616a287d1358984fc1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss : 3.358778476715088  Test PPL : 28.7540456819384\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## if test dataset has loss near around val loss that means we are not overfitting\n",
        "model = model.eval()\n",
        "trainer.test(model, dataloaders= test_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXUr_dXNuLOI"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJnYoK38uLOI"
      },
      "outputs": [],
      "source": [
        "en_vocab_lookup = {i:w for w,i in en_vocab.items()}\n",
        "\n",
        "def translate_sentence(sentence,model,en_nlp,de_nlp,en_vocab,de_vocab,lower,sos_token,eos_token,device,max_output_length=25):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        de_tokens = [token.text for token in de_nlp.tokenizer(sentence)]\n",
        "        if lower:\n",
        "            de_tokens = [token.lower() for token in de_tokens]\n",
        "        de_tokens = [sos_token] + de_tokens + [eos_token]\n",
        "\n",
        "        ids = [de_vocab.get(token, UNK_ID) for token in de_tokens]\n",
        "        tensor = torch.LongTensor(ids).unsqueeze(0).to(device)\n",
        "        encoder_outputs, hidden = model.encoder(tensor)\n",
        "\n",
        "\n",
        "        inputs = [en_vocab.get(sos_token)]\n",
        "        attentions = torch.zeros(max_output_length, 1, len(ids))\n",
        "\n",
        "        for i in range(max_output_length):\n",
        "            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
        "\n",
        "            # print(f'input tensor : {inputs_tensor.shape}')\n",
        "            # print(f'hidden : {hidden.shape}')\n",
        "            # print(f'encoder output : {encoder_outputs.shape}')\n",
        "\n",
        "            output, hidden, attention = model.decoder(inputs_tensor, hidden, encoder_outputs)\n",
        "            attentions[i] = attention\n",
        "            predicted_token = output.argmax(-1).item()\n",
        "            inputs.append(predicted_token)\n",
        "            if predicted_token == en_vocab[eos_token]:\n",
        "                break\n",
        "\n",
        "        en_tokens = [en_vocab_lookup.get(i) for i in inputs]\n",
        "    return en_tokens, de_tokens, attentions[: len(en_tokens) - 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR7-iPHluLOJ",
        "outputId": "048fee82-c161-40f2-dc6f-0c13bb0e4f62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.\n",
            "A man in an orange hat starring at something.\n"
          ]
        }
      ],
      "source": [
        "sentence = test_df.iloc[0]['de']\n",
        "expected_translation = test_df.iloc[0]['en']\n",
        "print(sentence)\n",
        "print(expected_translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoKijOYouLOJ"
      },
      "outputs": [],
      "source": [
        "translation, sentence_tokens, attention = translate_sentence(sentence,model,en_nlp,de_nlp,en_vocab,de_vocab,lower = True,sos_token = \"<sos>\",eos_token = \"<eos>\",device = \"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6okI_rmuLOJ",
        "outputId": "2a7c9c31-3d86-40ec-c462-98116479746e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pred :  ['<sos>', 'a', 'man', 'in', 'an', 'orange', 'hat', 'is', 'a', 'a', '.', '<eos>']\n",
            "True :  ['<sos>', 'ein', 'mann', 'mit', 'einem', 'orangefarbenen', 'hut', ',', 'der', 'etwas', 'anstarrt', '.', '<eos>']\n"
          ]
        }
      ],
      "source": [
        "print(\"Pred : \", translation)\n",
        "print(\"True : \", sentence_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty2Rnmh7uLOJ"
      },
      "outputs": [],
      "source": [
        "def plot_attention(sentence, translation, attention):\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    attention = attention.squeeze(1).numpy()\n",
        "    cax = ax.matshow(attention, cmap=\"bone\")\n",
        "    ax.set_xticks(ticks=np.arange(len(sentence)), labels=sentence, rotation=90, size=15)\n",
        "    translation = translation[1:]\n",
        "    ax.set_yticks(ticks=np.arange(len(translation)), labels=translation, size=15)\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97mAVP-0uLOJ",
        "outputId": "5d7c26af-b90d-4a1f-eeee-c19ee796fa0c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_attention(sentence_tokens, translation, attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4fZEpUQuLOJ"
      },
      "source": [
        "## Blue Scroe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydzill0AuLOJ",
        "outputId": "6e3be988-5bc7-4290-dbcb-e3266680ea3f",
        "colab": {
          "referenced_widgets": [
            "c31811ef3f7e4bd288b41836c8aa2bf2"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_24154/4149176577.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  translations = [translate_sentence(sent,model,en_nlp,de_nlp,en_vocab,de_vocab,lower = True,sos_token = \"<sos>\",eos_token = \"<eos>\",device = \"cuda\")[0] for sent in tqdm_notebook(test_df.de.values)]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c31811ef3f7e4bd288b41836c8aa2bf2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "translations = [translate_sentence(sent,model,en_nlp,de_nlp,en_vocab,de_vocab,lower = True,sos_token = \"<sos>\",eos_token = \"<eos>\",device = \"cuda\")[0] for sent in tqdm_notebook(test_df.de.values)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogH4ysu6uLOK",
        "outputId": "02e52020-7c64-4fb5-9884-7a88ea622e90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a man in an orange hat is a a .', 'a tri - dog runs along the grass in front of a white dog .']\n"
          ]
        }
      ],
      "source": [
        "predictions = [\" \".join(translation[1:-1]) for translation in translations]\n",
        "print(predictions[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykyI8qScuLOK",
        "outputId": "f919ed62-b97d-406e-f83d-4e0b4d9a6b90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a man in an orange hat starring at something.',\n",
            " 'a boston terrier is running on lush green grass in front of a white fence.']\n"
          ]
        }
      ],
      "source": [
        "references = test_df.en.str.lower().tolist()\n",
        "pprint(references[:2], compact=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yNiRmlZuLOK"
      },
      "outputs": [],
      "source": [
        "bleu = evaluate.load(\"bleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJVM4VmFuLOK"
      },
      "outputs": [],
      "source": [
        "def get_tokenizer_fn(nlp, lower):\n",
        "    def tokenizer_fn(s):\n",
        "        tokens = [token.text for token in nlp.tokenizer(s)]\n",
        "        if lower:\n",
        "            tokens = [token.lower() for token in tokens]\n",
        "        return tokens\n",
        "\n",
        "    return tokenizer_fn\n",
        "\n",
        "tokenizer_fn = get_tokenizer_fn(en_nlp,  lower = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jB8jVST1uLOL",
        "outputId": "20d2d98f-e771-4829-83ac-d2de684f0b99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bleu': 0.2091149147336781,\n",
              " 'precisions': [0.5317575406032483,\n",
              "  0.27517198248905567,\n",
              "  0.1503561736770692,\n",
              "  0.0869162342475908],\n",
              " 'brevity_penalty': 1.0,\n",
              " 'length_ratio': 1.0561298721188452,\n",
              " 'translation_length': 13792,\n",
              " 'reference_length': 13059}"
            ]
          },
          "execution_count": 180,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = bleu.compute(predictions=predictions, references=references, tokenizer=tokenizer_fn)\n",
        "results"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lighting",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}